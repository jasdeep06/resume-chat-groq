{"docstore/data": {"89bebc90-29e3-4ea3-b257-1fa684f0a406": {"__data__": {"id_": "89bebc90-29e3-4ea3-b257-1fa684f0a406", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "931848ac-0ee4-498a-a849-fe156f0dd378", "node_type": "1", "metadata": {}, "hash": "8dcffca54f8a7414b456a7577e0e117cfbcfce005327b36ec79788204c76be6e", "class_name": "RelatedNodeInfo"}}, "text": "4/5/24, 8:28 PM                                                        Getting Started with Tensorflow\n  Tensorflow                                                                                                                             HOME\n  Getting started with Tensorflow\n  It has been almost a year since Tensorflow was released by Google.Although there are a lot of deep learning libraries\n  available(like Theano etc.) but Tensorflow is pretty big!One of the prominent reason is being backed by the big\n  fish,Google! Also tensorflow has pretty great support for distributed systems.Considering the open-source popularity of\n  tensorflow and recent advancements in neural network research,this library is here to stay.\n  In this post we will not only introduce tensorflow but also take a under-the-hood trip to its working.We will start o\u25afby\n  going through basics of using tensorflow and analyze \u201ccomputational graphs\u201d that form the basis of tensorflow\u02bcs\n  working.Later we will build a linear regression model that would further clarify its working.\n  Lets get started!!!", "start_char_idx": 0, "end_char_idx": 1083, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "931848ac-0ee4-498a-a849-fe156f0dd378": {"__data__": {"id_": "931848ac-0ee4-498a-a849-fe156f0dd378", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89bebc90-29e3-4ea3-b257-1fa684f0a406", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "83e248cfd1cf2591b9d4521ba267dbb4594ea4707efdb94c5c5a97ab678cfbb4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "80339c25-1ba9-4e21-a9c2-a7c948a6dac0", "node_type": "1", "metadata": {}, "hash": "055611a37b530af151a23ea17c1e8a633fd51c89de6537ddf137df521d361b0d", "class_name": "RelatedNodeInfo"}}, "text": "When we come across the name \u201cTensorflow\u201d,the first thing that invariably comes to mind is the word \u201ctensor\u201d.Why\n  \u201ctensor\u201dflow?What is a \u201ctensor\u201d?Well,not dwelling too much on its mathematical representation,consider tensor as a\n  multidimensional array of numbers.Thus all scalars,vectors,matrices fall under the category of tensors. Let us try to add\n  two tensors in tensorflow-\n  #import tensorflow\n  import     tensorflow        as   tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name\"b\")\n  c=tf.add(a,b,name=\"c\")\n  In above program the function        tf.constant(value)           is used to declare a constant of value      value   and  tf.add(a,b)      is\n  used to add two tensors      a and  b. Let us now try to print the value of     c:\n  #import tensorflow\n  import     tensorflow        as   tf\n  #declare constants\n  a=tf.constant(2,", "start_char_idx": 1086, "end_char_idx": 1959, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "80339c25-1ba9-4e21-a9c2-a7c948a6dac0": {"__data__": {"id_": "80339c25-1ba9-4e21-a9c2-a7c948a6dac0", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "931848ac-0ee4-498a-a849-fe156f0dd378", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "fd888b580a202e94e7d0562d7b68a79a0abafd17ac07182f27e282cfb6229e9f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aa6b6ea7-da11-499c-8901-9a281b8ffc3b", "node_type": "1", "metadata": {}, "hash": "90ae5e5fd51ae64a8a936ca18aaabcfaa7f902df0d56913aecadb3234fe912aa", "class_name": "RelatedNodeInfo"}}, "text": "name=\"a\")\n  b=tf.constant(3,name=\"b\")\n  c=tf.add(a,b,name=\"c\")\n  print(c)\n  Output-\n  Tensor(\"Add:0\",           shape=(),      dtype=int32)\n  Instead of a scalar tensor valued 5,the above program prints a weird tensor object.Why does this happen?Well,at first it\n  might seem that the operations that we do in tensorflow are direct operations on multidimensional arrays but the truth\n  is drastically di\u25aferent.This di\u25aference is actually the essence of tensorflow! When we do computations in\n  tensorflow,instead of running them directly,tensorflow constructs a \u201ccomputation graph\u201d.", "start_char_idx": 1959, "end_char_idx": 2540, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "aa6b6ea7-da11-499c-8901-9a281b8ffc3b": {"__data__": {"id_": "aa6b6ea7-da11-499c-8901-9a281b8ffc3b", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "80339c25-1ba9-4e21-a9c2-a7c948a6dac0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "2f3fde0705e84fa8e27f577f0c2c2bab7e53d17121ba1c3b49d68a3f7e8f4618", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "831eb030-6685-420a-b9bc-6e37c3ac84d3", "node_type": "1", "metadata": {}, "hash": "21e4ff50d4d3a9669c2d233c15a1f975e24f5224f2a63b75541a0489ba01b844", "class_name": "RelatedNodeInfo"}}, "text": "Computation Graph\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                            1/104/5/24, 8:28 PM                                                       Getting Started with Tensorflow\n  Computation graph in tensorflow can be considered as network of nodes,with each node representing an\n  operation.From generation of constant tensors to mathematical operations on them,all are represented in form of nodes\n  and are referred to as ops.For our example of adding two constant tensors the computational graph can be visualized as:\n                                                       (add)\n                                                                                                 One of the important aspect of\n  computation graph is that it does not has any numerical value until it is explicitly evaluated or run.Thus when we printed\n  the value of  c above it returned a tensor object rather than returning the numerical value of added tensors.\n  So the next logical question is \u201chow do we run this computation graph?\u201d.", "start_char_idx": 2543, "end_char_idx": 3654, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "831eb030-6685-420a-b9bc-6e37c3ac84d3": {"__data__": {"id_": "831eb030-6685-420a-b9bc-6e37c3ac84d3", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aa6b6ea7-da11-499c-8901-9a281b8ffc3b", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "a86d6e56283f7f7c2caa4b153d58a972e40737e8f8f805af188fbbe2a99fbb33", "class_name": "RelatedNodeInfo"}}, "text": "In order to run a computation graph in tensorflow,a context is required.This context is encapsulated by aSession\n  object.To clarify this concept,have a look at the code below:\n  #import tensorflow\n  import     tensorflow        as  tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name=\"b\")\n  c=tf.add(a,b,name=\"c\")\n  #create a session\n  with    tf.Session()         as  sess:\n         #running the computation in session\n  Output-print(sess.run(c))\n  5\n  A Session object is created by the methodtf.Session().The computation                     c in our computation graph would run in\n  this session by calling the    sess.run(c)      method.The addition computation runs in our Sessionsess                 and yields a value\n  of5.", "start_char_idx": 3657, "end_char_idx": 4412, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "330b38d4-e0fe-4bcc-a10d-881dc5adf842": {"__data__": {"id_": "330b38d4-e0fe-4bcc-a10d-881dc5adf842", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4549ff7e-b52c-4a39-9df5-dff3fa83ee41", "node_type": "1", "metadata": {}, "hash": "4269ae115288c4dc2a81f3fa66ebae7c806ca40ed7b86097cc213b0cae0fb76e", "class_name": "RelatedNodeInfo"}}, "text": "4/5/24, 8:28 PM                                                        Getting Started with Tensorflow\n  Tensorflow                                                                                                                             HOME\n  Getting started with Tensorflow\n  It has been almost a year since Tensorflow was released by Google.Although there are a lot of deep learning libraries\n  available(like Theano etc.) but Tensorflow is pretty big!One of the prominent reason is being backed by the big\n  fish,Google! Also tensorflow has pretty great support for distributed systems.Considering the open-source popularity of\n  tensorflow and recent advancements in neural network research,this library is here to stay.\n  In this post we will not only introduce tensorflow but also take a under-the-hood trip to its working.We will start o\u25afby\n  going through basics of using tensorflow and analyze \u201ccomputational graphs\u201d that form the basis of tensorflow\u02bcs\n  working.Later we will build a linear regression model that would further clarify its working.\n  Lets get started!!!\n  When we come across the name \u201cTensorflow\u201d,the first thing that invariably comes to mind is the word \u201ctensor\u201d.Why\n  \u201ctensor\u201dflow?What is a \u201ctensor\u201d?Well,not dwelling too much on its mathematical representation,consider tensor as a\n  multidimensional array of numbers.Thus all scalars,vectors,matrices fall under the category of tensors.", "start_char_idx": 0, "end_char_idx": 1421, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "4549ff7e-b52c-4a39-9df5-dff3fa83ee41": {"__data__": {"id_": "4549ff7e-b52c-4a39-9df5-dff3fa83ee41", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "330b38d4-e0fe-4bcc-a10d-881dc5adf842", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "3651956572d1b891bccec1ef45321bcc898cfe660fecb168e9af8ef348c7d818", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c6384c47-fc7f-4126-87c9-303e1ce062cf", "node_type": "1", "metadata": {}, "hash": "21e4ff50d4d3a9669c2d233c15a1f975e24f5224f2a63b75541a0489ba01b844", "class_name": "RelatedNodeInfo"}}, "text": "Let us try to add\n  two tensors in tensorflow-\n  #import tensorflow\n  import     tensorflow        as   tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name\"b\")\n  c=tf.add(a,b,name=\"c\")\n  In above program the function        tf.constant(value)           is used to declare a constant of value      value   and  tf.add(a,b)      is\n  used to add two tensors      a and  b. Let us now try to print the value of     c:\n  #import tensorflow\n  import     tensorflow        as   tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name=\"b\")\n  c=tf.add(a,b,name=\"c\")\n  print(c)\n  Output-\n  Tensor(\"Add:0\",           shape=(),      dtype=int32)\n  Instead of a scalar tensor valued 5,the above program prints a weird tensor object.Why does this happen?Well,at first it\n  might seem that the operations that we do in tensorflow are direct operations on multidimensional arrays but the truth\n  is drastically di\u25aferent.This di\u25aference is actually the essence of tensorflow! When we do computations in\n  tensorflow,instead of running them directly,tensorflow constructs a \u201ccomputation graph\u201d.\n  Computation Graph\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                            1/104/5/24, 8:28 PM                                                       Getting Started with Tensorflow\n  Computation graph in tensorflow can be considered as network of nodes,with each node representing an\n  operation.From generation of constant tensors to mathematical operations on them,all are represented in form of nodes\n  and are referred to as ops.For our example of adding two constant tensors the computational graph can be visualized as:\n                                                       (add)\n                                                                                                 One of the important aspect of\n  computation graph is that it does not has any numerical value until it is explicitly evaluated or run.Thus when we printed\n  the value of  c above it returned a tensor object rather than returning the numerical value of added tensors.\n  So the next logical question is \u201chow do we run this computation graph?\u201d.", "start_char_idx": 1422, "end_char_idx": 3654, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "c6384c47-fc7f-4126-87c9-303e1ce062cf": {"__data__": {"id_": "c6384c47-fc7f-4126-87c9-303e1ce062cf", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4549ff7e-b52c-4a39-9df5-dff3fa83ee41", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "84e807eb71db684900500b1af9a6b100d2134a3979d2dc244510f8b01cbf8018", "class_name": "RelatedNodeInfo"}}, "text": "In order to run a computation graph in tensorflow,a context is required.This context is encapsulated by aSession\n  object.To clarify this concept,have a look at the code below:\n  #import tensorflow\n  import     tensorflow        as  tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name=\"b\")\n  c=tf.add(a,b,name=\"c\")\n  #create a session\n  with    tf.Session()         as  sess:\n         #running the computation in session\n  Output-print(sess.run(c))\n  5\n  A Session object is created by the methodtf.Session().The computation                     c in our computation graph would run in\n  this session by calling the    sess.run(c)      method.The addition computation runs in our Sessionsess                 and yields a value\n  of5.", "start_char_idx": 3657, "end_char_idx": 4412, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-0": {"__data__": {"id_": "node-0", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "536a18a120994697c34f860978153df8a148820b681d683b83f469453ed20945", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "70d9b4fc-e00d-41b0-bf8e-1454e4c9673a", "node_type": "1", "metadata": {}, "hash": "757f7dc02f91ada76c9e0e1a2f17ca190558fafebc92e969117595e3bc2a1e9e", "class_name": "RelatedNodeInfo"}}, "text": "4/5/24, 8:28 PM                                                        Getting Started with Tensorflow\n  Tensorflow                                                                                                                             HOME\n  Getting started with Tensorflow\n  It has been almost a year since Tensorflow was released by Google.Although there are a lot of deep learning libraries\n  available(like Theano etc.) but Tensorflow is pretty big!One of the prominent reason is being backed by the big\n  fish,Google! Also tensorflow has pretty great support for distributed systems.Considering the open-source popularity of\n  tensorflow and recent advancements in neural network research,this library is here to stay.\n  In this post we will not only introduce tensorflow but also take a under-the-hood trip to its working.We will start o\u25afby\n  going through basics of using tensorflow and analyze \u201ccomputational graphs\u201d that form the basis of tensorflow\u02bcs\n  working.Later we will build a linear regression model that would further clarify its working.\n  Lets get started!!!\n  When we come across the name \u201cTensorflow\u201d,the first thing that invariably comes to mind is the word \u201ctensor\u201d.Why\n  \u201ctensor\u201dflow?What is a \u201ctensor\u201d?Well,not dwelling too much on its mathematical representation,consider tensor as a\n  multidimensional array of numbers.Thus all scalars,vectors,matrices fall under the category of tensors. Let us try to add\n  two tensors in tensorflow-\n  #import tensorflow\n  import     tensorflow        as   tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name\"b\")\n  c=tf.add(a,b,name=\"c\")\n  In above program the function        tf.constant(value)           is used to declare a constant of value      value   and  tf.add(a,b)      is\n  used to add two tensors      a and  b. Let us now try to print the value of     c:\n  #import tensorflow\n  import     tensorflow        as   tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name=\"b\")\n  c=tf.add(a,b,name=\"c\")\n  print(c)\n  Output-\n  Tensor(\"Add:0\",           shape=(),      dtype=int32)\n  Instead of a scalar tensor valued 5,the above program prints a weird tensor object.Why does this happen?Well,at first it\n  might seem that the operations that we do in tensorflow are direct operations on multidimensional arrays but the truth\n  is drastically di\u25aferent.This di\u25aference is actually the essence of tensorflow! When we do computations in\n  tensorflow,instead of running them directly,tensorflow constructs a \u201ccomputation graph\u201d.\n  Computation Graph\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                            1/104/5/24, 8:28 PM                                                       Getting Started with Tensorflow\n  Computation graph in tensorflow can be considered as network of nodes,with each node representing an\n  operation.From generation of constant tensors to mathematical operations on them,all are represented in form of nodes\n  and are referred to as ops.For our example of adding two constant tensors the computational graph can be visualized as:\n                                                       (add)\n                                                                                                 One of the important aspect of\n  computation graph is that it does not has any numerical value until it is explicitly evaluated or run.Thus when we printed\n  the value of  c above it returned a tensor object rather than returning the numerical value of added tensors.\n  So the next logical question is \u201chow do we run this computation graph?\u201d.\n  In order to run a computation graph in tensorflow,a context is required.This context is encapsulated by aSession\n  object.To clarify this concept,have a look at the code below:\n  #import tensorflow\n  import     tensorflow        as  tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name=\"b\")\n  c=tf.add(a,b,name=\"c\")\n  #create a session\n  with    tf.Session()         as  sess:\n         #running the computation in session\n  Output-print(sess.run(c))\n  5\n  A Session object is created by the methodtf.Session().The computation                     c in our computation graph would run in\n  this session by calling the    sess.run(c)      method.The addition computation runs in our Sessionsess                 and yields a value\n  of5.", "start_char_idx": 0, "end_char_idx": 4412, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "5fc20f58-59f1-4ae3-ab61-9088e66f87c1": {"__data__": {"id_": "5fc20f58-59f1-4ae3-ab61-9088e66f87c1", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "dfb0d53bd85e32d61b1f08d4058983c88f9accd1021372fa441ca470fe28d717", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4cf01997-58ca-4208-be9d-171a951ce9f1", "node_type": "1", "metadata": {}, "hash": "356b9f4787a2123f344f4e84cddf493abae9e8784f5edcf8eef85575b34c111f", "class_name": "RelatedNodeInfo"}}, "text": "To avoid of passing the computation from the run method of our session object,tensorflow has concept of\n  Interactive Session.Once an InteractiveSession object is created,a computation can be evaluated by calling the                    eval()\n  method on it(instead of previously passing the computation from              run   method of Session object).This comes in handy\n  when dealing with Ipython notebooks and other interactive environments.Have a look at the implementation below:\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                            2/104/5/24, 8:28 PM                                                     Getting Started with Tensorflow\n  #import tensorflow\n  import     tensorflow       as  tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name=\"b\")\n  c=tf.add(a,b,name=\"c\")\n  #create an Interactive session\n  sess=tf.InteractiveSession()\n  #just call eval() on the computation to be evaluated.\n  print(c.eval())\n  Output-\n  5\n  Why does the concept of computation graph exist?", "start_char_idx": 0, "end_char_idx": 1096, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "4cf01997-58ca-4208-be9d-171a951ce9f1": {"__data__": {"id_": "4cf01997-58ca-4208-be9d-171a951ce9f1", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "dfb0d53bd85e32d61b1f08d4058983c88f9accd1021372fa441ca470fe28d717", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5fc20f58-59f1-4ae3-ab61-9088e66f87c1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "275560b87ba4fe3c2e4f3e0836c0aad0bd14c5413874f06e4cd870bf2a6f0e76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f5959ee9-403f-43eb-a196-e7efeeeca7f0", "node_type": "1", "metadata": {}, "hash": "2a66a6fccacd92f99300738021db50f4aaee92be7848e5e16219f2e509894889", "class_name": "RelatedNodeInfo"}}, "text": "One of the question that inevitably comes to mind while going through computation graph is the reason for existence of\n  such system.Why can\u02bct tensorflow do the computations directly on memory? Machine learning libraries like tensorflow\n  are needed to do large numerical computations e\u25aficiently.These computations are not optimised in python and need to\n  be carried out in a well optimised language outside python.Thus, there can be a lot of overhead from switching back to\n  Python a\u25afer every computation. This overhead is especially bad if you want to run computations on GPUs or in a\n  distributed manner, where there can be a high cost to transferring data. TensorFlow also does its heavy li\u25afing outside\n  Python, but it takes things a step further to avoid this overhead. Instead of running a single expensive operation\n  independently from Python, TensorFlow lets us describe a graph of interacting operations that run entirely outside\n  Python. This approach is similar to that used in Theano or Torch.\n  Tensorflow Variables\n  The tensors that we have dealt with till now were constants.Tensorflow also has the concept of Variables.", "start_char_idx": 1099, "end_char_idx": 2241, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "f5959ee9-403f-43eb-a196-e7efeeeca7f0": {"__data__": {"id_": "f5959ee9-403f-43eb-a196-e7efeeeca7f0", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "dfb0d53bd85e32d61b1f08d4058983c88f9accd1021372fa441ca470fe28d717", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4cf01997-58ca-4208-be9d-171a951ce9f1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "75da4cb53b4f448d6b50cba5df9557cc15d5519c5821b592855eb65cc4efe6db", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6f994e87-290d-4615-894e-6701ac41b1c9", "node_type": "1", "metadata": {}, "hash": "d51da102814ce907952c4349f8c52a6c871040016362cb28356bf2792cb67aad", "class_name": "RelatedNodeInfo"}}, "text": "Any machine\n  learning problem will inevitably involve some parameters that would need to be updated in order to optimize a\n  function.These updatable parameters will be expressed in form of tensorflow variables. One basic di\u25aference between\n  constant tensors and variable tensors is that the variable tensors need to be initialized explicitly unlike constant\n  tensors.Have a look at the implementation below:\n  #import tensorflow\n  import     tensorflow       as  tf\n  #add a constant tensor to our graph\n  W1=tf.ones((2,2))\n  #add a variable to our graph\n  W2=tf.Variable(tf.zeros((2,2)))\n  #make a session object\n  with    tf.Session()        as  sess:\n              #run the constant op\n        print(sess.run(W1))\n        #initialize all variables in our graph\n        sess.run(tf.global_variables_initializer())\n        #run the variable op\n        print(sess.run(W2))\n  Output-\n  [[   1.    1.]\n    [  1.    1.]]", "start_char_idx": 2242, "end_char_idx": 3162, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "6f994e87-290d-4615-894e-6701ac41b1c9": {"__data__": {"id_": "6f994e87-290d-4615-894e-6701ac41b1c9", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "dfb0d53bd85e32d61b1f08d4058983c88f9accd1021372fa441ca470fe28d717", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f5959ee9-403f-43eb-a196-e7efeeeca7f0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "a835e7eed9ec195c0469e968d69954c0544a5a70228f18edf5dfc6ffaa2f02b6", "class_name": "RelatedNodeInfo"}}, "text": "https://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                        3/104/5/24, 8:28 PM                                                      Getting Started with Tensorflow\n  [[   0.    0.]\n    [  0.    0.]]\n  The function   tf.global_variables_initializer()                  explicitly initializes all the variables tensors.The absence of this\n  function will lead to generation of error in presence of Variables.\n  Placeholders and Feed dictionaries\n  Till now we have seen simple variable tensors and constant tensors in tensorflow.A class of operations called\n  placeholder also exists to facilitate the input of data to the our computation graph.They act as dummy nodes that\n  provide entry points for data to our graph.", "start_char_idx": 3163, "end_char_idx": 3942, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "8c9df84a-8ac9-4936-affa-a661e204fc60": {"__data__": {"id_": "8c9df84a-8ac9-4936-affa-a661e204fc60", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "dfb0d53bd85e32d61b1f08d4058983c88f9accd1021372fa441ca470fe28d717", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5353846-d9e5-48d9-989d-04ebe4f803ce", "node_type": "1", "metadata": {}, "hash": "0a4a2995907696a3ff778924e0dd583d5af40a32cce3447468d61fe9e8fe3d64", "class_name": "RelatedNodeInfo"}}, "text": "To avoid of passing the computation from the run method of our session object,tensorflow has concept of\n  Interactive Session.Once an InteractiveSession object is created,a computation can be evaluated by calling the                    eval()\n  method on it(instead of previously passing the computation from              run   method of Session object).This comes in handy\n  when dealing with Ipython notebooks and other interactive environments.Have a look at the implementation below:\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                            2/104/5/24, 8:28 PM                                                     Getting Started with Tensorflow\n  #import tensorflow\n  import     tensorflow       as  tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name=\"b\")\n  c=tf.add(a,b,name=\"c\")\n  #create an Interactive session\n  sess=tf.InteractiveSession()\n  #just call eval() on the computation to be evaluated.\n  print(c.eval())\n  Output-\n  5\n  Why does the concept of computation graph exist?\n  One of the question that inevitably comes to mind while going through computation graph is the reason for existence of\n  such system.Why can\u02bct tensorflow do the computations directly on memory? Machine learning libraries like tensorflow\n  are needed to do large numerical computations e\u25aficiently.These computations are not optimised in python and need to\n  be carried out in a well optimised language outside python.Thus, there can be a lot of overhead from switching back to\n  Python a\u25afer every computation. This overhead is especially bad if you want to run computations on GPUs or in a\n  distributed manner, where there can be a high cost to transferring data. TensorFlow also does its heavy li\u25afing outside\n  Python, but it takes things a step further to avoid this overhead. Instead of running a single expensive operation\n  independently from Python, TensorFlow lets us describe a graph of interacting operations that run entirely outside\n  Python. This approach is similar to that used in Theano or Torch.\n  Tensorflow Variables\n  The tensors that we have dealt with till now were constants.Tensorflow also has the concept of Variables.", "start_char_idx": 0, "end_char_idx": 2241, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "b5353846-d9e5-48d9-989d-04ebe4f803ce": {"__data__": {"id_": "b5353846-d9e5-48d9-989d-04ebe4f803ce", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "dfb0d53bd85e32d61b1f08d4058983c88f9accd1021372fa441ca470fe28d717", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c9df84a-8ac9-4936-affa-a661e204fc60", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "91d05e00f0467aefab751a4877d90be134c54c329f36ef786c9e515c74615ff3", "class_name": "RelatedNodeInfo"}}, "text": "Any machine\n  learning problem will inevitably involve some parameters that would need to be updated in order to optimize a\n  function.These updatable parameters will be expressed in form of tensorflow variables. One basic di\u25aference between\n  constant tensors and variable tensors is that the variable tensors need to be initialized explicitly unlike constant\n  tensors.Have a look at the implementation below:\n  #import tensorflow\n  import     tensorflow       as  tf\n  #add a constant tensor to our graph\n  W1=tf.ones((2,2))\n  #add a variable to our graph\n  W2=tf.Variable(tf.zeros((2,2)))\n  #make a session object\n  with    tf.Session()        as  sess:\n              #run the constant op\n        print(sess.run(W1))\n        #initialize all variables in our graph\n        sess.run(tf.global_variables_initializer())\n        #run the variable op\n        print(sess.run(W2))\n  Output-\n  [[   1.    1.]\n    [  1.    1.]]\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                        3/104/5/24, 8:28 PM                                                      Getting Started with Tensorflow\n  [[   0.    0.]\n    [  0.    0.]]\n  The function   tf.global_variables_initializer()                  explicitly initializes all the variables tensors.The absence of this\n  function will lead to generation of error in presence of Variables.\n  Placeholders and Feed dictionaries\n  Till now we have seen simple variable tensors and constant tensors in tensorflow.A class of operations called\n  placeholder also exists to facilitate the input of data to the our computation graph.They act as dummy nodes that\n  provide entry points for data to our graph.", "start_char_idx": 2242, "end_char_idx": 3942, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-1": {"__data__": {"id_": "node-1", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "536a18a120994697c34f860978153df8a148820b681d683b83f469453ed20945", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "78bca4f6-6a9e-486e-8c3e-5b5b2ab63cac", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "43673100-8ccb-402b-9404-09633acba16e", "node_type": "1", "metadata": {}, "hash": "f5f9d87e2b201669dca9707aae8c5e170d326e15acb9a0e4abc2e9f7f063ea97", "class_name": "RelatedNodeInfo"}}, "text": "To avoid of passing the computation from the run method of our session object,tensorflow has concept of\n  Interactive Session.Once an InteractiveSession object is created,a computation can be evaluated by calling the                    eval()\n  method on it(instead of previously passing the computation from              run   method of Session object).This comes in handy\n  when dealing with Ipython notebooks and other interactive environments.Have a look at the implementation below:\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                            2/104/5/24, 8:28 PM                                                     Getting Started with Tensorflow\n  #import tensorflow\n  import     tensorflow       as  tf\n  #declare constants\n  a=tf.constant(2,name=\"a\")\n  b=tf.constant(3,name=\"b\")\n  c=tf.add(a,b,name=\"c\")\n  #create an Interactive session\n  sess=tf.InteractiveSession()\n  #just call eval() on the computation to be evaluated.\n  print(c.eval())\n  Output-\n  5\n  Why does the concept of computation graph exist?\n  One of the question that inevitably comes to mind while going through computation graph is the reason for existence of\n  such system.Why can\u02bct tensorflow do the computations directly on memory? Machine learning libraries like tensorflow\n  are needed to do large numerical computations e\u25aficiently.These computations are not optimised in python and need to\n  be carried out in a well optimised language outside python.Thus, there can be a lot of overhead from switching back to\n  Python a\u25afer every computation. This overhead is especially bad if you want to run computations on GPUs or in a\n  distributed manner, where there can be a high cost to transferring data. TensorFlow also does its heavy li\u25afing outside\n  Python, but it takes things a step further to avoid this overhead. Instead of running a single expensive operation\n  independently from Python, TensorFlow lets us describe a graph of interacting operations that run entirely outside\n  Python. This approach is similar to that used in Theano or Torch.\n  Tensorflow Variables\n  The tensors that we have dealt with till now were constants.Tensorflow also has the concept of Variables. Any machine\n  learning problem will inevitably involve some parameters that would need to be updated in order to optimize a\n  function.These updatable parameters will be expressed in form of tensorflow variables. One basic di\u25aference between\n  constant tensors and variable tensors is that the variable tensors need to be initialized explicitly unlike constant\n  tensors.Have a look at the implementation below:\n  #import tensorflow\n  import     tensorflow       as  tf\n  #add a constant tensor to our graph\n  W1=tf.ones((2,2))\n  #add a variable to our graph\n  W2=tf.Variable(tf.zeros((2,2)))\n  #make a session object\n  with    tf.Session()        as  sess:\n              #run the constant op\n        print(sess.run(W1))\n        #initialize all variables in our graph\n        sess.run(tf.global_variables_initializer())\n        #run the variable op\n        print(sess.run(W2))\n  Output-\n  [[   1.    1.]\n    [  1.    1.]]\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                        3/104/5/24, 8:28 PM                                                      Getting Started with Tensorflow\n  [[   0.    0.]\n    [  0.    0.]]\n  The function   tf.global_variables_initializer()                  explicitly initializes all the variables tensors.The absence of this\n  function will lead to generation of error in presence of Variables.\n  Placeholders and Feed dictionaries\n  Till now we have seen simple variable tensors and constant tensors in tensorflow.A class of operations called\n  placeholder also exists to facilitate the input of data to the our computation graph.They act as dummy nodes that\n  provide entry points for data to our graph.", "start_char_idx": 4413, "end_char_idx": 8355, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "e68a38cb-f389-4cf1-af4a-e53b68642dc2": {"__data__": {"id_": "e68a38cb-f389-4cf1-af4a-e53b68642dc2", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "899da2108893bf80bed5b908282d539a8c5c6af1bfe0cfc91f172a87bfdb6cf4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "830e74fe-453a-4474-b76c-6f7ba1260f39", "node_type": "1", "metadata": {}, "hash": "e903f8347f129a17825221eadeb6e7ad5e30b1079f2e7bcc9fb26dabcaeb833e", "class_name": "RelatedNodeInfo"}}, "text": "It is important to note that placeholder ops should be provided data at the\n  time of execution of our computation graph.This task is accomplished with the help of feed dictionaries.Thus feed\n  dictionaries act as an intermediate between our data and placeholder ops.On the other hand the placeholder ops\n  transfer the data that they receive from feed dictionaries at the time of execution to our computation graph.To get the\n  idea of syntax,have a look at the code below:\n  #import tensorflow\n  import     tensorflow       as  tf\n  #add a placeholder to our graph\n  input1=tf.placeholder(tf.float32)\n  #add another placeholder to our graph\n  input2=tf.placeholder(tf.float32)\n  #add an addition op to our graph\n  output=tf.add(input1,input2)\n  #create a session object\n  with    tf.Session()        as  sess:\n        #run the output op by providing data to placeholders through feed dictionaries\n        print(sess.run(output,feed_dict={input1:[3.],input2:[2.]}))\n  Output-\n  [  5.]", "start_char_idx": 0, "end_char_idx": 985, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "830e74fe-453a-4474-b76c-6f7ba1260f39": {"__data__": {"id_": "830e74fe-453a-4474-b76c-6f7ba1260f39", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "899da2108893bf80bed5b908282d539a8c5c6af1bfe0cfc91f172a87bfdb6cf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e68a38cb-f389-4cf1-af4a-e53b68642dc2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "7f0c9c22a07749af5c1cb073b2348e37a29fc7585b790389ba9ff3207e661f8c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0f72ad53-92b1-486e-9c63-6bdf6a1f613a", "node_type": "1", "metadata": {}, "hash": "41c66d10c0fe4ef14c537535d9d8b73f01a6e0313840303fdfad757b2f6733c2", "class_name": "RelatedNodeInfo"}}, "text": "The above code is heavily commented and self explanatory.One of the noticable modification is inclusion of the\n  argument    feed_dict     in the run()   methos of our session object. Note that above code is just to give you a syntactical\n  and logical feeling about placeholders and feed dictionaries.We will use this concept at scale when we implement linear\n  regression model in tensorflow.To clarify further,the flow of data fromfeed_dict               to placeholders can be graphically\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                        4/104/5/24, 8:28 PM                                                   Getting Started with Tensorflow\n represented as:                    feed_dict-{input1-[-~linputz-[_~}}\n         inputI=tf placeholder(tf.float32)                                       input2-tf placeholder(tf.float32)\n                                                                 output\n Now that we have some idea of how computations take place in tensorflow,it is now a good time to implement a real\n model in tensorflow and analyze its working hands-on.Let us implement simple linear regression in tensorflow and\n string together all that we have learnt in this post.", "start_char_idx": 988, "end_char_idx": 2262, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "0f72ad53-92b1-486e-9c63-6bdf6a1f613a": {"__data__": {"id_": "0f72ad53-92b1-486e-9c63-6bdf6a1f613a", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "899da2108893bf80bed5b908282d539a8c5c6af1bfe0cfc91f172a87bfdb6cf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "830e74fe-453a-4474-b76c-6f7ba1260f39", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "85ba85de7670a0eb6180c74f0806dfe6e0ed4b31a1b08022fc59623c3b3898f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5647289-b088-4eb3-be1d-47671a8660c8", "node_type": "1", "metadata": {}, "hash": "7853e9b81cd962c8afd1fc1255255c813c04a374add1ed0904c2a4a944649dbb", "class_name": "RelatedNodeInfo"}}, "text": "Linear Regression in tensorflow\n The problem of linear regression is arguably the simplest machine learning problem.Simply put,in a 2-dimensional\n context,given a set of points(data),we need to find a straight line that fits that data the best.We will implement this\n model by breaking it down in steps and using concepts that we have learnt so far in this post.", "start_char_idx": 2264, "end_char_idx": 2626, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "b5647289-b088-4eb3-be1d-47671a8660c8": {"__data__": {"id_": "b5647289-b088-4eb3-be1d-47671a8660c8", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "899da2108893bf80bed5b908282d539a8c5c6af1bfe0cfc91f172a87bfdb6cf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0f72ad53-92b1-486e-9c63-6bdf6a1f613a", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "a61e12aec31e4e2af981f3ab216667eb48cc4d63b9fcaa9f08d6f4ff2fa7973d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f0c93be2-836d-4b5e-80b6-949ccb78b9c1", "node_type": "1", "metadata": {}, "hash": "24d2fe3648ef301638f34521d7eec0f880715bae0983589ce5224025e24f73fe", "class_name": "RelatedNodeInfo"}}, "text": "First things first,we need a dataset to implement regression on.Let us generate some random data as-\n  #importing tensorflow\n  import    tensorflow      as   tf\n  #importing numpy\n  import    numpy    as  np\n  #importing matplotlib for plots\n  import    matplotlib.pyplot          as  plt\n  #x coordinate of data\n  X_data=np.arange(0,100,0.1)\n  #y coordinate of data\n  Y_data=X_data+20*np.sin(X_data/10)\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                        5/104/5/24, 8:28 PM                                                  Getting Started with Tensorflow\n  #plotting the data\n  plt.scatter(X_data,Y_data)\n  plt.show()\n Above code is pretty straightforward.To generate data we add some sinosoidal noise to the y coordinate.This give us the\n following plot:\n            100\n                                     20                                                                   100\n Our task is to fit a best possible straight line through this dataset.", "start_char_idx": 2628, "end_char_idx": 3653, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "f0c93be2-836d-4b5e-80b6-949ccb78b9c1": {"__data__": {"id_": "f0c93be2-836d-4b5e-80b6-949ccb78b9c1", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "899da2108893bf80bed5b908282d539a8c5c6af1bfe0cfc91f172a87bfdb6cf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5647289-b088-4eb3-be1d-47671a8660c8", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "11d4ccf8a0409c2395ee91545c1da37d38759aee10f8e9e8c977ad97274d7113", "class_name": "RelatedNodeInfo"}}, "text": "Now that we have our input data,we need to process it\n so that we can transfer it to our model.We have 1000 data-points of bothX_dataand             Y_data. Let us convert this data in\n form of 1000X1 tensors as-\n  #total data points\n  n_samples=1000\n  #X_data in form of 1000X1 tensor\n  X_data=np.reshape(X_data,(n_samples,1))\n  #Y_data in form of 1000X1 tensor\n  Y_data=np.reshape(Y_data,(n_samples,1))\n Now that we have our data processed,we need to declare placeholders which would act as entry point of data to our\n computation graph.Here we will not transfer all of our 1000 datapoints at once to our computation graph.Rather we will\n do this in batches of size 100.", "start_char_idx": 3654, "end_char_idx": 4326, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "8d1e3dc3-06c4-4708-b13e-dc8da1ce3465": {"__data__": {"id_": "8d1e3dc3-06c4-4708-b13e-dc8da1ce3465", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "899da2108893bf80bed5b908282d539a8c5c6af1bfe0cfc91f172a87bfdb6cf4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2017a454-3321-4576-b9d6-48a4771cd4bb", "node_type": "1", "metadata": {}, "hash": "82227cd3aff9d7fc95bc8619647a6aa8eca40639c1a6451b084844340374fdbd", "class_name": "RelatedNodeInfo"}}, "text": "It is important to note that placeholder ops should be provided data at the\n  time of execution of our computation graph.This task is accomplished with the help of feed dictionaries.Thus feed\n  dictionaries act as an intermediate between our data and placeholder ops.On the other hand the placeholder ops\n  transfer the data that they receive from feed dictionaries at the time of execution to our computation graph.To get the\n  idea of syntax,have a look at the code below:\n  #import tensorflow\n  import     tensorflow       as  tf\n  #add a placeholder to our graph\n  input1=tf.placeholder(tf.float32)\n  #add another placeholder to our graph\n  input2=tf.placeholder(tf.float32)\n  #add an addition op to our graph\n  output=tf.add(input1,input2)\n  #create a session object\n  with    tf.Session()        as  sess:\n        #run the output op by providing data to placeholders through feed dictionaries\n        print(sess.run(output,feed_dict={input1:[3.],input2:[2.]}))\n  Output-\n  [  5.]\n  The above code is heavily commented and self explanatory.One of the noticable modification is inclusion of the\n  argument    feed_dict     in the run()   methos of our session object. Note that above code is just to give you a syntactical\n  and logical feeling about placeholders and feed dictionaries.We will use this concept at scale when we implement linear\n  regression model in tensorflow.To clarify further,the flow of data fromfeed_dict               to placeholders can be graphically\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                        4/104/5/24, 8:28 PM                                                   Getting Started with Tensorflow\n represented as:                    feed_dict-{input1-[-~linputz-[_~}}\n         inputI=tf placeholder(tf.float32)                                       input2-tf placeholder(tf.float32)\n                                                                 output\n Now that we have some idea of how computations take place in tensorflow,it is now a good time to implement a real\n model in tensorflow and analyze its working hands-on.Let us implement simple linear regression in tensorflow and\n string together all that we have learnt in this post.", "start_char_idx": 0, "end_char_idx": 2262, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "2017a454-3321-4576-b9d6-48a4771cd4bb": {"__data__": {"id_": "2017a454-3321-4576-b9d6-48a4771cd4bb", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "899da2108893bf80bed5b908282d539a8c5c6af1bfe0cfc91f172a87bfdb6cf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8d1e3dc3-06c4-4708-b13e-dc8da1ce3465", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "b1d2bc4652f41c2cc40f64baa0f385903211acb5a82064344e432ad23b4742a8", "class_name": "RelatedNodeInfo"}}, "text": "Linear Regression in tensorflow\n The problem of linear regression is arguably the simplest machine learning problem.Simply put,in a 2-dimensional\n context,given a set of points(data),we need to find a straight line that fits that data the best.We will implement this\n model by breaking it down in steps and using concepts that we have learnt so far in this post.\n First things first,we need a dataset to implement regression on.Let us generate some random data as-\n  #importing tensorflow\n  import    tensorflow      as   tf\n  #importing numpy\n  import    numpy    as  np\n  #importing matplotlib for plots\n  import    matplotlib.pyplot          as  plt\n  #x coordinate of data\n  X_data=np.arange(0,100,0.1)\n  #y coordinate of data\n  Y_data=X_data+20*np.sin(X_data/10)\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                        5/104/5/24, 8:28 PM                                                  Getting Started with Tensorflow\n  #plotting the data\n  plt.scatter(X_data,Y_data)\n  plt.show()\n Above code is pretty straightforward.To generate data we add some sinosoidal noise to the y coordinate.This give us the\n following plot:\n            100\n                                     20                                                                   100\n Our task is to fit a best possible straight line through this dataset. Now that we have our input data,we need to process it\n so that we can transfer it to our model.We have 1000 data-points of bothX_dataand             Y_data. Let us convert this data in\n form of 1000X1 tensors as-\n  #total data points\n  n_samples=1000\n  #X_data in form of 1000X1 tensor\n  X_data=np.reshape(X_data,(n_samples,1))\n  #Y_data in form of 1000X1 tensor\n  Y_data=np.reshape(Y_data,(n_samples,1))\n Now that we have our data processed,we need to declare placeholders which would act as entry point of data to our\n computation graph.Here we will not transfer all of our 1000 datapoints at once to our computation graph.Rather we will\n do this in batches of size 100.", "start_char_idx": 2264, "end_char_idx": 4326, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-2": {"__data__": {"id_": "node-2", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "536a18a120994697c34f860978153df8a148820b681d683b83f469453ed20945", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "70d9b4fc-e00d-41b0-bf8e-1454e4c9673a", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "dfb0d53bd85e32d61b1f08d4058983c88f9accd1021372fa441ca470fe28d717", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "19a7140e-c41d-4386-aff4-7aaabd3745a9", "node_type": "1", "metadata": {}, "hash": "7429bdd8dbd5c35bae967f7e76068335c0ae3beb6c3f96e7cbd2d8f8747bfd57", "class_name": "RelatedNodeInfo"}}, "text": "It is important to note that placeholder ops should be provided data at the\n  time of execution of our computation graph.This task is accomplished with the help of feed dictionaries.Thus feed\n  dictionaries act as an intermediate between our data and placeholder ops.On the other hand the placeholder ops\n  transfer the data that they receive from feed dictionaries at the time of execution to our computation graph.To get the\n  idea of syntax,have a look at the code below:\n  #import tensorflow\n  import     tensorflow       as  tf\n  #add a placeholder to our graph\n  input1=tf.placeholder(tf.float32)\n  #add another placeholder to our graph\n  input2=tf.placeholder(tf.float32)\n  #add an addition op to our graph\n  output=tf.add(input1,input2)\n  #create a session object\n  with    tf.Session()        as  sess:\n        #run the output op by providing data to placeholders through feed dictionaries\n        print(sess.run(output,feed_dict={input1:[3.],input2:[2.]}))\n  Output-\n  [  5.]\n  The above code is heavily commented and self explanatory.One of the noticable modification is inclusion of the\n  argument    feed_dict     in the run()   methos of our session object. Note that above code is just to give you a syntactical\n  and logical feeling about placeholders and feed dictionaries.We will use this concept at scale when we implement linear\n  regression model in tensorflow.To clarify further,the flow of data fromfeed_dict               to placeholders can be graphically\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                        4/104/5/24, 8:28 PM                                                   Getting Started with Tensorflow\n represented as:                    feed_dict-{input1-[-~linputz-[_~}}\n         inputI=tf placeholder(tf.float32)                                       input2-tf placeholder(tf.float32)\n                                                                 output\n Now that we have some idea of how computations take place in tensorflow,it is now a good time to implement a real\n model in tensorflow and analyze its working hands-on.Let us implement simple linear regression in tensorflow and\n string together all that we have learnt in this post.\n Linear Regression in tensorflow\n The problem of linear regression is arguably the simplest machine learning problem.Simply put,in a 2-dimensional\n context,given a set of points(data),we need to find a straight line that fits that data the best.We will implement this\n model by breaking it down in steps and using concepts that we have learnt so far in this post.\n First things first,we need a dataset to implement regression on.Let us generate some random data as-\n  #importing tensorflow\n  import    tensorflow      as   tf\n  #importing numpy\n  import    numpy    as  np\n  #importing matplotlib for plots\n  import    matplotlib.pyplot          as  plt\n  #x coordinate of data\n  X_data=np.arange(0,100,0.1)\n  #y coordinate of data\n  Y_data=X_data+20*np.sin(X_data/10)\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                        5/104/5/24, 8:28 PM                                                  Getting Started with Tensorflow\n  #plotting the data\n  plt.scatter(X_data,Y_data)\n  plt.show()\n Above code is pretty straightforward.To generate data we add some sinosoidal noise to the y coordinate.This give us the\n following plot:\n            100\n                                     20                                                                   100\n Our task is to fit a best possible straight line through this dataset. Now that we have our input data,we need to process it\n so that we can transfer it to our model.We have 1000 data-points of bothX_dataand             Y_data. Let us convert this data in\n form of 1000X1 tensors as-\n  #total data points\n  n_samples=1000\n  #X_data in form of 1000X1 tensor\n  X_data=np.reshape(X_data,(n_samples,1))\n  #Y_data in form of 1000X1 tensor\n  Y_data=np.reshape(Y_data,(n_samples,1))\n Now that we have our data processed,we need to declare placeholders which would act as entry point of data to our\n computation graph.Here we will not transfer all of our 1000 datapoints at once to our computation graph.Rather we will\n do this in batches of size 100.", "start_char_idx": 8356, "end_char_idx": 12682, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "cdc60b01-0486-4ddb-9e4c-2a08b06e3771": {"__data__": {"id_": "cdc60b01-0486-4ddb-9e4c-2a08b06e3771", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-3", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "3d2bbfc3956643057f84bbec8424b9fe01e50685e05960bd02a59397721756ca", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9bac13a0-3a8b-47f3-b4b6-2f1b7bb396b5", "node_type": "1", "metadata": {}, "hash": "784670d4a02ddf9e296cd69d64d4481a55529fba99e18eb3a676c7160be2a154", "class_name": "RelatedNodeInfo"}}, "text": "#batch size\n  batch_size=100\n  #placeholder for X_data\n  X=tf.placeholder(tf.float32,shape=(batch_size,1))\n  #placeholder for Y_data\n  Y=tf.placeholder(tf.float32,shape=(batch_size,1))\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                 6/104/5/24, 8:28 PM                                                    Getting Started with Tensorflow\n  We have our placeholders ready.As we want to fit our data in a straight line,we need to dwell upon the variables that\n  would be learnt in order to accomplish this task.We need to create a weight variable and a bias variable to generate\n  predictions from our input data X.These predictions will be modified by updating weight and bias variables.Our aim\n  would be to get our predictions as close as possible to      Y.This e\u25afect would be captured by minimizing our root mean\n  square error loss function.\n  #defining weight variable\n  W=tf.Variable(tf.random_normal((1,1)),name=\"weights\")\n  #defining bias variable\n  b=tf.Variable(tf.", "start_char_idx": 0, "end_char_idx": 1056, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-3", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "9bac13a0-3a8b-47f3-b4b6-2f1b7bb396b5": {"__data__": {"id_": "9bac13a0-3a8b-47f3-b4b6-2f1b7bb396b5", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-3", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "3d2bbfc3956643057f84bbec8424b9fe01e50685e05960bd02a59397721756ca", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cdc60b01-0486-4ddb-9e4c-2a08b06e3771", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "79806740e89c49f7eb9bf96d8f4a31780430607df8e4fb7752e22ec7fb5efa6c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f78de0e9-aa74-4fdc-9f02-f9614ed325c4", "node_type": "1", "metadata": {}, "hash": "2d75970412d9de51a4e6ceb3bdab588906770fad9762701f5d1de29172efae21", "class_name": "RelatedNodeInfo"}}, "text": "random_normal((1,)),name=\"bias\")\n  #generating predictions\n  y_pred=tf.matmul(X,W)+b\n  #RMSE loss function\n  loss=tf.reduce_sum(((Y-y_pred)**2)/n_samples)\n  To get the minimum value of this loss function we need to vary the values of weights and bias.This minimization is\n  achieved using gradient-descent(referhere) which is implemented directly in tensorflow as follows:\n  #defining optimizer\n  opt_operation=tf.trainAdamOptimizer().minimize(loss)\n  #creating a session object\n  with    tf.Session()       as   sess:\n        #initializing the variables\n        sess.run(tf.global_variables_initializer())\n        #gradient descent loop for 500 steps\n        for   iteration      in   range(500):\n           #selecting batches randomly\n           indices=np.random.choice(n_samples,batch_size)\n           X_batch,Y_batch=X_data[indices],Y_data[indices]\n           #running gradient descent step\n           _,loss_value=sess.run([opt_operation,loss],feed_dict={X:X_batch,", "start_char_idx": 1056, "end_char_idx": 2027, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-3", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "f78de0e9-aa74-4fdc-9f02-f9614ed325c4": {"__data__": {"id_": "f78de0e9-aa74-4fdc-9f02-f9614ed325c4", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-3", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "3d2bbfc3956643057f84bbec8424b9fe01e50685e05960bd02a59397721756ca", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9bac13a0-3a8b-47f3-b4b6-2f1b7bb396b5", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "362eca81563cecf5613d4f37a0bdda76705f16f5e6ca9978ea1d5e0b4203903d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "04182ad6-d538-4c8b-9458-687f608aa90e", "node_type": "1", "metadata": {}, "hash": "e4ab15a497d70631559e5c886551fdb51998ac6f2393b1adf6a2d546305d2ba5", "class_name": "RelatedNodeInfo"}}, "text": "y:Y_batch})\n  Above we define a optimization operation using thetf.trainAdamOptimizer()function which is a modified form of\n  gradient descent algorithm.We also randomly select the batches of input data of batch size 100 and run our optimization\n  operation.Thefor     loop running 500 times during the training can be seen as 500 iterations in the gradient descent\n  algorithm.A\u25afer each iteration the values of weights and bias are updated.Each iteration randomly selects\n  100(batch_size) data points from the set of 1000(n_samples) and feeds it to the placeholders using feed dictionaries.", "start_char_idx": 2027, "end_char_idx": 2619, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-3", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "04182ad6-d538-4c8b-9458-687f608aa90e": {"__data__": {"id_": "04182ad6-d538-4c8b-9458-687f608aa90e", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-3", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "3d2bbfc3956643057f84bbec8424b9fe01e50685e05960bd02a59397721756ca", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f78de0e9-aa74-4fdc-9f02-f9614ed325c4", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "f57930d644611ec1d2f96c5f08df5eb39dd69bf499c97020ea4695bab934f540", "class_name": "RelatedNodeInfo"}}, "text": "When we plot the straight line generated along with our initial dataset we see the following:\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                         7/104/5/24, 8:28 PM                                           Getting Started with Tensorflow\n       100\n                                                                    100          Thus we can see that we have\n obtained a pretty good linear fit to our curve.For the sake of completeness here is the full code:\n  import   tensorflow    as  tf\n  import   numpy   as np\n  import   matplotlib.pyplot      as  plt\n  #generating data\n  X_data=np.arange(0,100,0.1)\n  Y_data=X_data+20*np.sin(X_data/10)\n  #plotting the data\n  plt.scatter(X_data,Y_data)\n  #Uncomment below to see the plot of input data.", "start_char_idx": 2622, "end_char_idx": 3438, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-3", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "718e3d55-64f2-47ae-9bed-dc7a9f800dc8": {"__data__": {"id_": "718e3d55-64f2-47ae-9bed-dc7a9f800dc8", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-3", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "3d2bbfc3956643057f84bbec8424b9fe01e50685e05960bd02a59397721756ca", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d3f479d-0dd5-4ba1-a932-a257db6f633a", "node_type": "1", "metadata": {}, "hash": "5b8b8e1ef7329957a4746a217d92d36ee9007edc17d9b85534f93f830e419275", "class_name": "RelatedNodeInfo"}}, "text": "#batch size\n  batch_size=100\n  #placeholder for X_data\n  X=tf.placeholder(tf.float32,shape=(batch_size,1))\n  #placeholder for Y_data\n  Y=tf.placeholder(tf.float32,shape=(batch_size,1))\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                 6/104/5/24, 8:28 PM                                                    Getting Started with Tensorflow\n  We have our placeholders ready.As we want to fit our data in a straight line,we need to dwell upon the variables that\n  would be learnt in order to accomplish this task.We need to create a weight variable and a bias variable to generate\n  predictions from our input data X.These predictions will be modified by updating weight and bias variables.Our aim\n  would be to get our predictions as close as possible to      Y.This e\u25afect would be captured by minimizing our root mean\n  square error loss function.", "start_char_idx": 0, "end_char_idx": 926, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-3", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "4d3f479d-0dd5-4ba1-a932-a257db6f633a": {"__data__": {"id_": "4d3f479d-0dd5-4ba1-a932-a257db6f633a", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-3", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "3d2bbfc3956643057f84bbec8424b9fe01e50685e05960bd02a59397721756ca", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "718e3d55-64f2-47ae-9bed-dc7a9f800dc8", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "c8f34406fab4c010f8161864d3c54c23e9f7a02e85b1475f5129df87f5917240", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "94906e28-116a-44f1-be7e-8abdf7cf9afd", "node_type": "1", "metadata": {}, "hash": "e4ab15a497d70631559e5c886551fdb51998ac6f2393b1adf6a2d546305d2ba5", "class_name": "RelatedNodeInfo"}}, "text": "#defining weight variable\n  W=tf.Variable(tf.random_normal((1,1)),name=\"weights\")\n  #defining bias variable\n  b=tf.Variable(tf.random_normal((1,)),name=\"bias\")\n  #generating predictions\n  y_pred=tf.matmul(X,W)+b\n  #RMSE loss function\n  loss=tf.reduce_sum(((Y-y_pred)**2)/n_samples)\n  To get the minimum value of this loss function we need to vary the values of weights and bias.This minimization is\n  achieved using gradient-descent(referhere) which is implemented directly in tensorflow as follows:\n  #defining optimizer\n  opt_operation=tf.trainAdamOptimizer().minimize(loss)\n  #creating a session object\n  with    tf.Session()       as   sess:\n        #initializing the variables\n        sess.run(tf.global_variables_initializer())\n        #gradient descent loop for 500 steps\n        for   iteration      in   range(500):\n           #selecting batches randomly\n           indices=np.random.choice(n_samples,batch_size)\n           X_batch,Y_batch=X_data[indices],Y_data[indices]\n           #running gradient descent step\n           _,loss_value=sess.run([opt_operation,loss],feed_dict={X:X_batch,y:Y_batch})\n  Above we define a optimization operation using thetf.trainAdamOptimizer()function which is a modified form of\n  gradient descent algorithm.We also randomly select the batches of input data of batch size 100 and run our optimization\n  operation.Thefor     loop running 500 times during the training can be seen as 500 iterations in the gradient descent\n  algorithm.A\u25afer each iteration the values of weights and bias are updated.Each iteration randomly selects\n  100(batch_size) data points from the set of 1000(n_samples) and feeds it to the placeholders using feed dictionaries.", "start_char_idx": 929, "end_char_idx": 2619, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-3", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "94906e28-116a-44f1-be7e-8abdf7cf9afd": {"__data__": {"id_": "94906e28-116a-44f1-be7e-8abdf7cf9afd", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-3", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "3d2bbfc3956643057f84bbec8424b9fe01e50685e05960bd02a59397721756ca", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d3f479d-0dd5-4ba1-a932-a257db6f633a", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "ac986bed5e2877d29d288fc014402fc86b608ec4c240abc137ca53a8a1c1fad4", "class_name": "RelatedNodeInfo"}}, "text": "When we plot the straight line generated along with our initial dataset we see the following:\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                         7/104/5/24, 8:28 PM                                           Getting Started with Tensorflow\n       100\n                                                                    100          Thus we can see that we have\n obtained a pretty good linear fit to our curve.For the sake of completeness here is the full code:\n  import   tensorflow    as  tf\n  import   numpy   as np\n  import   matplotlib.pyplot      as  plt\n  #generating data\n  X_data=np.arange(0,100,0.1)\n  Y_data=X_data+20*np.sin(X_data/10)\n  #plotting the data\n  plt.scatter(X_data,Y_data)\n  #Uncomment below to see the plot of input data.", "start_char_idx": 2622, "end_char_idx": 3438, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-3", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-3": {"__data__": {"id_": "node-3", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "536a18a120994697c34f860978153df8a148820b681d683b83f469453ed20945", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "43673100-8ccb-402b-9404-09633acba16e", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "899da2108893bf80bed5b908282d539a8c5c6af1bfe0cfc91f172a87bfdb6cf4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "33efd5b4-9080-42de-843f-9fd074216280", "node_type": "1", "metadata": {}, "hash": "546e1a7f30149aecbb746abbfbb867cc97005280e04468a4d7365eb41da0aad9", "class_name": "RelatedNodeInfo"}}, "text": "#batch size\n  batch_size=100\n  #placeholder for X_data\n  X=tf.placeholder(tf.float32,shape=(batch_size,1))\n  #placeholder for Y_data\n  Y=tf.placeholder(tf.float32,shape=(batch_size,1))\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                                 6/104/5/24, 8:28 PM                                                    Getting Started with Tensorflow\n  We have our placeholders ready.As we want to fit our data in a straight line,we need to dwell upon the variables that\n  would be learnt in order to accomplish this task.We need to create a weight variable and a bias variable to generate\n  predictions from our input data X.These predictions will be modified by updating weight and bias variables.Our aim\n  would be to get our predictions as close as possible to      Y.This e\u25afect would be captured by minimizing our root mean\n  square error loss function.\n  #defining weight variable\n  W=tf.Variable(tf.random_normal((1,1)),name=\"weights\")\n  #defining bias variable\n  b=tf.Variable(tf.random_normal((1,)),name=\"bias\")\n  #generating predictions\n  y_pred=tf.matmul(X,W)+b\n  #RMSE loss function\n  loss=tf.reduce_sum(((Y-y_pred)**2)/n_samples)\n  To get the minimum value of this loss function we need to vary the values of weights and bias.This minimization is\n  achieved using gradient-descent(referhere) which is implemented directly in tensorflow as follows:\n  #defining optimizer\n  opt_operation=tf.trainAdamOptimizer().minimize(loss)\n  #creating a session object\n  with    tf.Session()       as   sess:\n        #initializing the variables\n        sess.run(tf.global_variables_initializer())\n        #gradient descent loop for 500 steps\n        for   iteration      in   range(500):\n           #selecting batches randomly\n           indices=np.random.choice(n_samples,batch_size)\n           X_batch,Y_batch=X_data[indices],Y_data[indices]\n           #running gradient descent step\n           _,loss_value=sess.run([opt_operation,loss],feed_dict={X:X_batch,y:Y_batch})\n  Above we define a optimization operation using thetf.trainAdamOptimizer()function which is a modified form of\n  gradient descent algorithm.We also randomly select the batches of input data of batch size 100 and run our optimization\n  operation.Thefor     loop running 500 times during the training can be seen as 500 iterations in the gradient descent\n  algorithm.A\u25afer each iteration the values of weights and bias are updated.Each iteration randomly selects\n  100(batch_size) data points from the set of 1000(n_samples) and feeds it to the placeholders using feed dictionaries.\n  When we plot the straight line generated along with our initial dataset we see the following:\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                         7/104/5/24, 8:28 PM                                           Getting Started with Tensorflow\n       100\n                                                                    100          Thus we can see that we have\n obtained a pretty good linear fit to our curve.For the sake of completeness here is the full code:\n  import   tensorflow    as  tf\n  import   numpy   as np\n  import   matplotlib.pyplot      as  plt\n  #generating data\n  X_data=np.arange(0,100,0.1)\n  Y_data=X_data+20*np.sin(X_data/10)\n  #plotting the data\n  plt.scatter(X_data,Y_data)\n  #Uncomment below to see the plot of input data.", "start_char_idx": 12685, "end_char_idx": 16123, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-3", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "19c9ebb1-b44c-40a1-b337-6e77a4e18874": {"__data__": {"id_": "19c9ebb1-b44c-40a1-b337-6e77a4e18874", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-4", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "425f3143df4f8e969384626e9c2392aa7d9a46827dfaa61e88126f4cc587eee5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fbd5e353-710b-4456-acb2-d5af7de11925", "node_type": "1", "metadata": {}, "hash": "f63daa3628998189879e8f91f8cdd5c6b41ab58eacb974277c2721c46b91c18b", "class_name": "RelatedNodeInfo"}}, "text": "#plt.show()\n  n_samples=1000\n  X_data=np.reshape(X_data,(n_samples,1))\n  Y_data=np.reshape(Y_data,(n_samples,1))\n  #batch size\n  batch_size=100\n  #placeholder for X_data\n  X=tf.placeholder(tf.float32,shape=(batch_size,1))\n  #placeholder for Y_data\n  Y=tf.placeholder(tf.float32,shape=(batch_size,1))\n  #placeholder for checking the validity of our model after training\n  X_check=tf.placeholder(tf.float32,shape=(n_samples,1))\n  #defining weight variable\n  W=tf.Variable(tf.random_normal((1,1)),name=\"weights\")\n  #defining bias variable\n  b=tf.Variable(tf.random_normal((1,)),name=\"bias\")\n  #generating predictions\n  y_pred=tf.matmul(X,W)+b\n  #RMSE loss function\n  loss=tf.reduce_sum(((Y-y_pred)**2)/batch_size)\n  #defining optimizer\n  opt_operation=tf.train.AdamOptimizer(.0001).", "start_char_idx": 0, "end_char_idx": 779, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-4", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "fbd5e353-710b-4456-acb2-d5af7de11925": {"__data__": {"id_": "fbd5e353-710b-4456-acb2-d5af7de11925", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-4", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "425f3143df4f8e969384626e9c2392aa7d9a46827dfaa61e88126f4cc587eee5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "19c9ebb1-b44c-40a1-b337-6e77a4e18874", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "28b8808544bcd497513031e9b509d85d158c34b93db854d2c9f326a8e8e4c8f7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "07ed620d-990a-4645-917a-f9ff7baa9449", "node_type": "1", "metadata": {}, "hash": "4c58299bd94a9ac5a54dd7cbfb95986c2ec7506da0911e02e861afc5b562c3d4", "class_name": "RelatedNodeInfo"}}, "text": "minimize(loss)\n  #creating a session object\n  with  tf.Session()     as  sess:\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                             8/104/5/24, 8:28 PM                                                Getting Started with Tensorflow\n        #initializing the variables\n        sess.run(tf.global_variables_initializer())\n        #gradient descent loop for 500 steps\n        for   iteration     in  range(5000):\n              #selecting batches randomly\n              indices=np.random.choice(n_samples,batch_size)\n              X_batch,Y_batch=X_data[indices],Y_data[indices]\n              #running gradient descent step\n              _,loss_value=sess.run([opt_operation,loss],feed_dict={X:X_batch,Y:Y_batch})\n        #plotting the predictions\n        y_check=tf.matmul(X_check,W)+b\n        pred=sess.run(y_check,feed_dict={X_check:X_data})\n        plt.scatter(X_data,pred)\n        plt.scatter(X_data,Y_data)\n        plt.", "start_char_idx": 779, "end_char_idx": 1757, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-4", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "07ed620d-990a-4645-917a-f9ff7baa9449": {"__data__": {"id_": "07ed620d-990a-4645-917a-f9ff7baa9449", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-4", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "425f3143df4f8e969384626e9c2392aa7d9a46827dfaa61e88126f4cc587eee5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fbd5e353-710b-4456-acb2-d5af7de11925", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "0402c5436b0951c2ce60a4acd4d75c4ee00499a6aeee49b1d0e047a206a00bb6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b719517-ebe5-495b-b68e-d1a6bfe56239", "node_type": "1", "metadata": {}, "hash": "f948ea588aa26ac0a074f526ffae52aff63d9369a132f73d86fd09199f6a0e45", "class_name": "RelatedNodeInfo"}}, "text": "show()\n  So this was our implementation of linear regression model in tensorflow.In the next post we will try to extend our\n  knowledge of tensorflow by building a di\u25aferent model.It would be fun!Stay tuned!", "start_char_idx": 1757, "end_char_idx": 1963, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-4", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "0b719517-ebe5-495b-b68e-d1a6bfe56239": {"__data__": {"id_": "0b719517-ebe5-495b-b68e-d1a6bfe56239", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-4", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "425f3143df4f8e969384626e9c2392aa7d9a46827dfaa61e88126f4cc587eee5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07ed620d-990a-4645-917a-f9ff7baa9449", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "94786272961a9469e3f48d6d1a5a5eb07c9eaf3bc2acf4d30148929b7de26997", "class_name": "RelatedNodeInfo"}}, "text": "ALSO ON JASDEEP06                                Posted on 26 January,2017\n    Further-into-               Lets-Practice -             Variable-sharing-in-        Understanding LSTM in\n     Further-into-\n     Further-into-              Lets-Practice-\n                                Lets-Practice-              Variable-sharing-in-\n                                                            Variable-sharing-in-        Understanding LSTM in\n                                                                                        Understanding LSTM in\n    backpropagation             Backpropagation             Tensorflow                  Tensorflow\n     backpropagation\n     backpropagation            Backpropagation\n                                Backpropagation             Tensor\u25afow\n                                                            Tensor\u25afow                   Tensor\u25afow\n     7 years ago2 comments                                                              Tensor\u25afow\n              \u2022                 7 years ago4 comments\n                                         \u2022                  7 years ago14 comments\n                                                                     \u2022                  7 years ago32 comments\n                                                                                                 \u2022\n     Backpropagation : Further  Lets-practice-              Tensorflow: Variable sharingCNNs in Tensorflow(cifar-\n     into Backpropagation       backpropagation             in Tensorflow               10)\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                    9/10", "start_char_idx": 1967, "end_char_idx": 3628, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-4", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "1f9d67e3-dc73-4fec-9b45-640f88878d19": {"__data__": {"id_": "1f9d67e3-dc73-4fec-9b45-640f88878d19", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-4", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "425f3143df4f8e969384626e9c2392aa7d9a46827dfaa61e88126f4cc587eee5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d5697707-4412-480c-93ea-6c595ef7a1ba", "node_type": "1", "metadata": {}, "hash": "f948ea588aa26ac0a074f526ffae52aff63d9369a132f73d86fd09199f6a0e45", "class_name": "RelatedNodeInfo"}}, "text": "#plt.show()\n  n_samples=1000\n  X_data=np.reshape(X_data,(n_samples,1))\n  Y_data=np.reshape(Y_data,(n_samples,1))\n  #batch size\n  batch_size=100\n  #placeholder for X_data\n  X=tf.placeholder(tf.float32,shape=(batch_size,1))\n  #placeholder for Y_data\n  Y=tf.placeholder(tf.float32,shape=(batch_size,1))\n  #placeholder for checking the validity of our model after training\n  X_check=tf.placeholder(tf.float32,shape=(n_samples,1))\n  #defining weight variable\n  W=tf.Variable(tf.random_normal((1,1)),name=\"weights\")\n  #defining bias variable\n  b=tf.Variable(tf.random_normal((1,)),name=\"bias\")\n  #generating predictions\n  y_pred=tf.matmul(X,W)+b\n  #RMSE loss function\n  loss=tf.reduce_sum(((Y-y_pred)**2)/batch_size)\n  #defining optimizer\n  opt_operation=tf.train.AdamOptimizer(.0001).minimize(loss)\n  #creating a session object\n  with  tf.Session()     as  sess:\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                             8/104/5/24, 8:28 PM                                                Getting Started with Tensorflow\n        #initializing the variables\n        sess.run(tf.global_variables_initializer())\n        #gradient descent loop for 500 steps\n        for   iteration     in  range(5000):\n              #selecting batches randomly\n              indices=np.random.choice(n_samples,batch_size)\n              X_batch,Y_batch=X_data[indices],Y_data[indices]\n              #running gradient descent step\n              _,loss_value=sess.run([opt_operation,loss],feed_dict={X:X_batch,Y:Y_batch})\n        #plotting the predictions\n        y_check=tf.matmul(X_check,W)+b\n        pred=sess.run(y_check,feed_dict={X_check:X_data})\n        plt.scatter(X_data,pred)\n        plt.scatter(X_data,Y_data)\n        plt.show()\n  So this was our implementation of linear regression model in tensorflow.In the next post we will try to extend our\n  knowledge of tensorflow by building a di\u25aferent model.It would be fun!Stay tuned!", "start_char_idx": 0, "end_char_idx": 1963, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-4", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "d5697707-4412-480c-93ea-6c595ef7a1ba": {"__data__": {"id_": "d5697707-4412-480c-93ea-6c595ef7a1ba", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-4", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "425f3143df4f8e969384626e9c2392aa7d9a46827dfaa61e88126f4cc587eee5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1f9d67e3-dc73-4fec-9b45-640f88878d19", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "15e8e3bc72ea75ce4bcaa569b62ce6970b81ae65d6ae21de7493e53f48ad8d01", "class_name": "RelatedNodeInfo"}}, "text": "ALSO ON JASDEEP06                                Posted on 26 January,2017\n    Further-into-               Lets-Practice -             Variable-sharing-in-        Understanding LSTM in\n     Further-into-\n     Further-into-              Lets-Practice-\n                                Lets-Practice-              Variable-sharing-in-\n                                                            Variable-sharing-in-        Understanding LSTM in\n                                                                                        Understanding LSTM in\n    backpropagation             Backpropagation             Tensorflow                  Tensorflow\n     backpropagation\n     backpropagation            Backpropagation\n                                Backpropagation             Tensor\u25afow\n                                                            Tensor\u25afow                   Tensor\u25afow\n     7 years ago2 comments                                                              Tensor\u25afow\n              \u2022                 7 years ago4 comments\n                                         \u2022                  7 years ago14 comments\n                                                                     \u2022                  7 years ago32 comments\n                                                                                                 \u2022\n     Backpropagation : Further  Lets-practice-              Tensorflow: Variable sharingCNNs in Tensorflow(cifar-\n     into Backpropagation       backpropagation             in Tensorflow               10)\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                    9/10", "start_char_idx": 1967, "end_char_idx": 3628, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-4", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-4": {"__data__": {"id_": "node-4", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "536a18a120994697c34f860978153df8a148820b681d683b83f469453ed20945", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "19a7140e-c41d-4386-aff4-7aaabd3745a9", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}, "hash": "3d2bbfc3956643057f84bbec8424b9fe01e50685e05960bd02a59397721756ca", "class_name": "RelatedNodeInfo"}}, "text": "#plt.show()\n  n_samples=1000\n  X_data=np.reshape(X_data,(n_samples,1))\n  Y_data=np.reshape(Y_data,(n_samples,1))\n  #batch size\n  batch_size=100\n  #placeholder for X_data\n  X=tf.placeholder(tf.float32,shape=(batch_size,1))\n  #placeholder for Y_data\n  Y=tf.placeholder(tf.float32,shape=(batch_size,1))\n  #placeholder for checking the validity of our model after training\n  X_check=tf.placeholder(tf.float32,shape=(n_samples,1))\n  #defining weight variable\n  W=tf.Variable(tf.random_normal((1,1)),name=\"weights\")\n  #defining bias variable\n  b=tf.Variable(tf.random_normal((1,)),name=\"bias\")\n  #generating predictions\n  y_pred=tf.matmul(X,W)+b\n  #RMSE loss function\n  loss=tf.reduce_sum(((Y-y_pred)**2)/batch_size)\n  #defining optimizer\n  opt_operation=tf.train.AdamOptimizer(.0001).minimize(loss)\n  #creating a session object\n  with  tf.Session()     as  sess:\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                             8/104/5/24, 8:28 PM                                                Getting Started with Tensorflow\n        #initializing the variables\n        sess.run(tf.global_variables_initializer())\n        #gradient descent loop for 500 steps\n        for   iteration     in  range(5000):\n              #selecting batches randomly\n              indices=np.random.choice(n_samples,batch_size)\n              X_batch,Y_batch=X_data[indices],Y_data[indices]\n              #running gradient descent step\n              _,loss_value=sess.run([opt_operation,loss],feed_dict={X:X_batch,Y:Y_batch})\n        #plotting the predictions\n        y_check=tf.matmul(X_check,W)+b\n        pred=sess.run(y_check,feed_dict={X_check:X_data})\n        plt.scatter(X_data,pred)\n        plt.scatter(X_data,Y_data)\n        plt.show()\n  So this was our implementation of linear regression model in tensorflow.In the next post we will try to extend our\n  knowledge of tensorflow by building a di\u25aferent model.It would be fun!Stay tuned!\n   ALSO ON JASDEEP06                                Posted on 26 January,2017\n    Further-into-               Lets-Practice -             Variable-sharing-in-        Understanding LSTM in\n     Further-into-\n     Further-into-              Lets-Practice-\n                                Lets-Practice-              Variable-sharing-in-\n                                                            Variable-sharing-in-        Understanding LSTM in\n                                                                                        Understanding LSTM in\n    backpropagation             Backpropagation             Tensorflow                  Tensorflow\n     backpropagation\n     backpropagation            Backpropagation\n                                Backpropagation             Tensor\u25afow\n                                                            Tensor\u25afow                   Tensor\u25afow\n     7 years ago2 comments                                                              Tensor\u25afow\n              \u2022                 7 years ago4 comments\n                                         \u2022                  7 years ago14 comments\n                                                                     \u2022                  7 years ago32 comments\n                                                                                                 \u2022\n     Backpropagation : Further  Lets-practice-              Tensorflow: Variable sharingCNNs in Tensorflow(cifar-\n     into Backpropagation       backpropagation             in Tensorflow               10)\nhttps://jasdeep06.github.io/posts/getting-started-with-tensorflow/                                                    9/10", "start_char_idx": 16126, "end_char_idx": 19754, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-4", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "654a2ae2-5b35-4a5a-9a85-51a4c338c26c": {"__data__": {"id_": "654a2ae2-5b35-4a5a-9a85-51a4c338c26c", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "Getting Started with Tensorflow", "path": "cache\\blogposts\\Getting-Started-with-Tensorflow\\parsed\\images\\b32c93eb-6e8c-4bfa-8091-3ede9f98b868-img_p1_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "In the context of TensorFlow, a computation graph can be visualized as a network where nodes represent operations. For instance, when adding two constant tensors, the graph would consist of three nodes. Two of these nodes would represent the constants being added, and the third node would represent the addition operation itself. The constants could be labeled with identifiers such as \"a\" and \"b,\" and the addition operation could be labeled as \"c\" or more descriptively with \"(add)\" to indicate the nature of the operation. The nodes representing the constants would not have any inherent numerical value until the computation is run within a TensorFlow session. When the computation is executed, for example, by using the `sess.run(c)` command within a session, the result of the addition operation would be computed and could yield a numerical value, such as 5, if the constants were 2 and 3, respectively. This execution model allows for the construction of complex computational graphs that are only evaluated when needed, providing flexibility and efficiency in numerical computations.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6b024260-b27d-4a50-ad09-056f3591de55": {"__data__": {"id_": "6b024260-b27d-4a50-ad09-056f3591de55", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "Getting Started with Tensorflow", "path": "cache\\blogposts\\Getting-Started-with-Tensorflow\\parsed\\images\\b32c93eb-6e8c-4bfa-8091-3ede9f98b868-img_p4_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The content you provided discusses the basics of getting started with TensorFlow, a popular open-source library for numerical computation and machine learning. It introduces the concept of placeholders in TensorFlow, which are used to feed input data into a TensorFlow computation graph. Placeholders can be thought of as empty nodes that will be filled with data when the graph is executed. In the context of TensorFlow, a placeholder for a float32 data type is created, which is a common practice when setting up inputs for a model.\n\nThe text then transitions into explaining linear regression within the TensorFlow framework. Linear regression is a foundational algorithm in machine learning, where the goal is to find the best-fitting straight line through a set of data points in a two-dimensional space. This is typically one of the first algorithms that beginners learn when they start with machine learning because of its simplicity and the clear intuition behind it.\n\nTo implement linear regression, the text suggests generating a dataset using NumPy, a library for scientific computing in Python, and visualizing it with Matplotlib, a plotting library for Python. The dataset is created by generating x-coordinates and corresponding y-coordinates, where the y-coordinates are a function of the x-coordinates with some added noise to simulate real-world data.\n\nThe source link provided at the end of the text points to a tutorial or blog post that likely contains more detailed information and examples on how to get started with TensorFlow and implement linear regression.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3b9ad336-9ee3-4249-ab68-cecffeff8e54": {"__data__": {"id_": "3b9ad336-9ee3-4249-ab68-cecffeff8e54", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "Getting Started with Tensorflow", "path": "cache\\blogposts\\Getting-Started-with-Tensorflow\\parsed\\images\\b32c93eb-6e8c-4bfa-8091-3ede9f98b868-img_p5_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The visual representation you're referring to illustrates a scatter plot that has been created using a dataset where the y-coordinates have been modified with sinusoidal noise. This results in a non-linear distribution of data points that appear to follow a wave-like pattern. The plot likely shows a range of x-values on the horizontal axis, which could be from 0 to 100, and a corresponding range of y-values on the vertical axis. The y-values exhibit variation due to the added noise, which is intended to simulate real-world data where measurements are not perfectly linear or predictable.\n\nThe goal mentioned is to find the best possible straight line that can approximate the underlying relationship between the x and y values in this dataset. To achieve this, the data is being prepared for processing by converting it into tensors, which are multi-dimensional arrays that are suitable for input into machine learning models. The data is organized into 1000x1 tensors to match the number of data points, and placeholders are set up in the computational graph to handle the data in smaller batches for efficiency during the training process. The batch size specified is 100, indicating that the model will process the data in subsets of 100 data points at a time.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3016c498-bcec-4fcf-ba1b-70309b2761a2": {"__data__": {"id_": "3016c498-bcec-4fcf-ba1b-70309b2761a2", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "Getting Started with Tensorflow", "path": "cache\\blogposts\\Getting-Started-with-Tensorflow\\parsed\\images\\b32c93eb-6e8c-4bfa-8091-3ede9f98b868-img_p7_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The content you provided suggests that a linear regression model has been implemented using TensorFlow, a popular machine learning library. The code generates a dataset with a linear relationship that is perturbed by a sinusoidal noise, which is a common way to simulate real-world data where the relationship between variables is not perfectly linear due to various factors.\n\nThe dataset is created by generating a range of values from 0 to 100 in increments of 0.1. To these values, a sinusoidal function is applied to introduce variability, simulating a real-world scenario where data points deviate from a perfect linear relationship. The resulting dataset is then plotted to visualize the distribution of data points and the underlying pattern they follow.\n\nThe code snippet also includes the setup for a TensorFlow session, where placeholders for the input data (X) and output data (Y) are defined, along with variables for the model's weights and bias. The model predicts the output (y_pred) as a linear combination of the input and the weights, with the bias added. The loss function used is the Root Mean Square Error (RMSE), which measures the average magnitude of the errors between the predicted values and the actual values. An optimizer is employed to minimize this loss function, thereby improving the model's weight and bias parameters.\n\nThe optimizer chosen is the Adam optimizer, a popular choice for training neural networks due to its efficiency and adaptive learning rate properties. The code is structured to run within a TensorFlow session, which is the environment where the operations", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"89bebc90-29e3-4ea3-b257-1fa684f0a406": {"doc_hash": "83e248cfd1cf2591b9d4521ba267dbb4594ea4707efdb94c5c5a97ab678cfbb4", "ref_doc_id": "node-0"}, "931848ac-0ee4-498a-a849-fe156f0dd378": {"doc_hash": "fd888b580a202e94e7d0562d7b68a79a0abafd17ac07182f27e282cfb6229e9f", "ref_doc_id": "node-0"}, "80339c25-1ba9-4e21-a9c2-a7c948a6dac0": {"doc_hash": "2f3fde0705e84fa8e27f577f0c2c2bab7e53d17121ba1c3b49d68a3f7e8f4618", "ref_doc_id": "node-0"}, "aa6b6ea7-da11-499c-8901-9a281b8ffc3b": {"doc_hash": "a86d6e56283f7f7c2caa4b153d58a972e40737e8f8f805af188fbbe2a99fbb33", "ref_doc_id": "node-0"}, "831eb030-6685-420a-b9bc-6e37c3ac84d3": {"doc_hash": "22583d51e8cf0c659f4845763c8a76df4ffcc17805ccbcdf629150a9750307b8", "ref_doc_id": "node-0"}, "330b38d4-e0fe-4bcc-a10d-881dc5adf842": {"doc_hash": "3651956572d1b891bccec1ef45321bcc898cfe660fecb168e9af8ef348c7d818", "ref_doc_id": "node-0"}, "4549ff7e-b52c-4a39-9df5-dff3fa83ee41": {"doc_hash": "84e807eb71db684900500b1af9a6b100d2134a3979d2dc244510f8b01cbf8018", "ref_doc_id": "node-0"}, "c6384c47-fc7f-4126-87c9-303e1ce062cf": {"doc_hash": "22583d51e8cf0c659f4845763c8a76df4ffcc17805ccbcdf629150a9750307b8", "ref_doc_id": "node-0"}, "node-0": {"doc_hash": "689b7171832867e9059403366b13c098ffd9116dab50d0e8c8e5102755a982ac", "ref_doc_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439"}, "5fc20f58-59f1-4ae3-ab61-9088e66f87c1": {"doc_hash": "275560b87ba4fe3c2e4f3e0836c0aad0bd14c5413874f06e4cd870bf2a6f0e76", "ref_doc_id": "node-1"}, "4cf01997-58ca-4208-be9d-171a951ce9f1": {"doc_hash": "75da4cb53b4f448d6b50cba5df9557cc15d5519c5821b592855eb65cc4efe6db", "ref_doc_id": "node-1"}, "f5959ee9-403f-43eb-a196-e7efeeeca7f0": {"doc_hash": "a835e7eed9ec195c0469e968d69954c0544a5a70228f18edf5dfc6ffaa2f02b6", "ref_doc_id": "node-1"}, "6f994e87-290d-4615-894e-6701ac41b1c9": {"doc_hash": "4f770912caa1ea9c7a91f8a68206e0c1415b59f2345541882834bf60edc34a30", "ref_doc_id": "node-1"}, "8c9df84a-8ac9-4936-affa-a661e204fc60": {"doc_hash": "91d05e00f0467aefab751a4877d90be134c54c329f36ef786c9e515c74615ff3", "ref_doc_id": "node-1"}, "b5353846-d9e5-48d9-989d-04ebe4f803ce": {"doc_hash": "7b994f0a3b050feb3e03907989d864f927fa57d0c2635ce8fc1da4e7887a00eb", "ref_doc_id": "node-1"}, "node-1": {"doc_hash": "dfb0d53bd85e32d61b1f08d4058983c88f9accd1021372fa441ca470fe28d717", "ref_doc_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439"}, "e68a38cb-f389-4cf1-af4a-e53b68642dc2": {"doc_hash": "7f0c9c22a07749af5c1cb073b2348e37a29fc7585b790389ba9ff3207e661f8c", "ref_doc_id": "node-2"}, "830e74fe-453a-4474-b76c-6f7ba1260f39": {"doc_hash": "85ba85de7670a0eb6180c74f0806dfe6e0ed4b31a1b08022fc59623c3b3898f8", "ref_doc_id": "node-2"}, "0f72ad53-92b1-486e-9c63-6bdf6a1f613a": {"doc_hash": "a61e12aec31e4e2af981f3ab216667eb48cc4d63b9fcaa9f08d6f4ff2fa7973d", "ref_doc_id": "node-2"}, "b5647289-b088-4eb3-be1d-47671a8660c8": {"doc_hash": "11d4ccf8a0409c2395ee91545c1da37d38759aee10f8e9e8c977ad97274d7113", "ref_doc_id": "node-2"}, "f0c93be2-836d-4b5e-80b6-949ccb78b9c1": {"doc_hash": "64da5ea44e94ed285b069a5ee0ee9a91bc6739f8ceb11a1bbc634417da199189", "ref_doc_id": "node-2"}, "8d1e3dc3-06c4-4708-b13e-dc8da1ce3465": {"doc_hash": "b1d2bc4652f41c2cc40f64baa0f385903211acb5a82064344e432ad23b4742a8", "ref_doc_id": "node-2"}, "2017a454-3321-4576-b9d6-48a4771cd4bb": {"doc_hash": "859fa6490d2ced3f881d506401ab4c5b97dd9a81378f58f719c4676af7d16f0b", "ref_doc_id": "node-2"}, "node-2": {"doc_hash": "899da2108893bf80bed5b908282d539a8c5c6af1bfe0cfc91f172a87bfdb6cf4", "ref_doc_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439"}, "cdc60b01-0486-4ddb-9e4c-2a08b06e3771": {"doc_hash": "79806740e89c49f7eb9bf96d8f4a31780430607df8e4fb7752e22ec7fb5efa6c", "ref_doc_id": "node-3"}, "9bac13a0-3a8b-47f3-b4b6-2f1b7bb396b5": {"doc_hash": "362eca81563cecf5613d4f37a0bdda76705f16f5e6ca9978ea1d5e0b4203903d", "ref_doc_id": "node-3"}, "f78de0e9-aa74-4fdc-9f02-f9614ed325c4": {"doc_hash": "f57930d644611ec1d2f96c5f08df5eb39dd69bf499c97020ea4695bab934f540", "ref_doc_id": "node-3"}, "04182ad6-d538-4c8b-9458-687f608aa90e": {"doc_hash": "c2414d8cca2ed84aae565f548ad8ae43d52a9a2c302b4b5564db7d1caa1c988b", "ref_doc_id": "node-3"}, "718e3d55-64f2-47ae-9bed-dc7a9f800dc8": {"doc_hash": "c8f34406fab4c010f8161864d3c54c23e9f7a02e85b1475f5129df87f5917240", "ref_doc_id": "node-3"}, "4d3f479d-0dd5-4ba1-a932-a257db6f633a": {"doc_hash": "ac986bed5e2877d29d288fc014402fc86b608ec4c240abc137ca53a8a1c1fad4", "ref_doc_id": "node-3"}, "94906e28-116a-44f1-be7e-8abdf7cf9afd": {"doc_hash": "c2414d8cca2ed84aae565f548ad8ae43d52a9a2c302b4b5564db7d1caa1c988b", "ref_doc_id": "node-3"}, "node-3": {"doc_hash": "3d2bbfc3956643057f84bbec8424b9fe01e50685e05960bd02a59397721756ca", "ref_doc_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439"}, "19c9ebb1-b44c-40a1-b337-6e77a4e18874": {"doc_hash": "28b8808544bcd497513031e9b509d85d158c34b93db854d2c9f326a8e8e4c8f7", "ref_doc_id": "node-4"}, "fbd5e353-710b-4456-acb2-d5af7de11925": {"doc_hash": "0402c5436b0951c2ce60a4acd4d75c4ee00499a6aeee49b1d0e047a206a00bb6", "ref_doc_id": "node-4"}, "07ed620d-990a-4645-917a-f9ff7baa9449": {"doc_hash": "94786272961a9469e3f48d6d1a5a5eb07c9eaf3bc2acf4d30148929b7de26997", "ref_doc_id": "node-4"}, "0b719517-ebe5-495b-b68e-d1a6bfe56239": {"doc_hash": "f85d52ea77d5a757f401869232e8513b0164a8c96e63247da847506bdea9c64a", "ref_doc_id": "node-4"}, "1f9d67e3-dc73-4fec-9b45-640f88878d19": {"doc_hash": "15e8e3bc72ea75ce4bcaa569b62ce6970b81ae65d6ae21de7493e53f48ad8d01", "ref_doc_id": "node-4"}, "d5697707-4412-480c-93ea-6c595ef7a1ba": {"doc_hash": "f85d52ea77d5a757f401869232e8513b0164a8c96e63247da847506bdea9c64a", "ref_doc_id": "node-4"}, "node-4": {"doc_hash": "425f3143df4f8e969384626e9c2392aa7d9a46827dfaa61e88126f4cc587eee5", "ref_doc_id": "b3fbd31e-9706-4195-98ba-f6e9e3c45439"}, "654a2ae2-5b35-4a5a-9a85-51a4c338c26c": {"doc_hash": "495b1c480f0cf435d74bf9de0cbfa87a9702bb2782903894d03b549bd5d17a30"}, "6b024260-b27d-4a50-ad09-056f3591de55": {"doc_hash": "077fd742f1e0298bf741506de00391853048489414ca1587683e9a3214e7d9fa"}, "3b9ad336-9ee3-4249-ab68-cecffeff8e54": {"doc_hash": "e4386a8635ab13ba630260501243ca4c1ac40488bee0b25a093dc831b2897d62"}, "3016c498-bcec-4fcf-ba1b-70309b2761a2": {"doc_hash": "a891a854fb4b5ab7697354dbd3fc46fe8e6540faae117e2e1f6b81795aea548e"}}, "docstore/ref_doc_info": {"node-0": {"node_ids": ["89bebc90-29e3-4ea3-b257-1fa684f0a406", "931848ac-0ee4-498a-a849-fe156f0dd378", "80339c25-1ba9-4e21-a9c2-a7c948a6dac0", "aa6b6ea7-da11-499c-8901-9a281b8ffc3b", "831eb030-6685-420a-b9bc-6e37c3ac84d3", "330b38d4-e0fe-4bcc-a10d-881dc5adf842", "4549ff7e-b52c-4a39-9df5-dff3fa83ee41", "c6384c47-fc7f-4126-87c9-303e1ce062cf"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}}, "b3fbd31e-9706-4195-98ba-f6e9e3c45439": {"node_ids": ["node-0", "node-1", "node-2", "node-3", "node-4"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}}, "node-1": {"node_ids": ["5fc20f58-59f1-4ae3-ab61-9088e66f87c1", "4cf01997-58ca-4208-be9d-171a951ce9f1", "f5959ee9-403f-43eb-a196-e7efeeeca7f0", "6f994e87-290d-4615-894e-6701ac41b1c9", "8c9df84a-8ac9-4936-affa-a661e204fc60", "b5353846-d9e5-48d9-989d-04ebe4f803ce"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}}, "node-2": {"node_ids": ["e68a38cb-f389-4cf1-af4a-e53b68642dc2", "830e74fe-453a-4474-b76c-6f7ba1260f39", "0f72ad53-92b1-486e-9c63-6bdf6a1f613a", "b5647289-b088-4eb3-be1d-47671a8660c8", "f0c93be2-836d-4b5e-80b6-949ccb78b9c1", "8d1e3dc3-06c4-4708-b13e-dc8da1ce3465", "2017a454-3321-4576-b9d6-48a4771cd4bb"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}}, "node-3": {"node_ids": ["cdc60b01-0486-4ddb-9e4c-2a08b06e3771", "9bac13a0-3a8b-47f3-b4b6-2f1b7bb396b5", "f78de0e9-aa74-4fdc-9f02-f9614ed325c4", "04182ad6-d538-4c8b-9458-687f608aa90e", "718e3d55-64f2-47ae-9bed-dc7a9f800dc8", "4d3f479d-0dd5-4ba1-a932-a257db6f633a", "94906e28-116a-44f1-be7e-8abdf7cf9afd"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}}, "node-4": {"node_ids": ["19c9ebb1-b44c-40a1-b337-6e77a4e18874", "fbd5e353-710b-4456-acb2-d5af7de11925", "07ed620d-990a-4645-917a-f9ff7baa9449", "0b719517-ebe5-495b-b68e-d1a6bfe56239", "1f9d67e3-dc73-4fec-9b45-640f88878d19", "d5697707-4412-480c-93ea-6c595ef7a1ba"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "Getting Started with Tensorflow"}}}}