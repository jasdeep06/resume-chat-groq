{"docstore/data": {"5dad8c33-d152-4251-86de-d4c9e08cfc34": {"__data__": {"id_": "5dad8c33-d152-4251-86de-d4c9e08cfc34", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b40a4533-3bae-4625-9427-9019419569d9", "node_type": "1", "metadata": {}, "hash": "ca6c77866de6f39987adbb4a8d533c91daf5beab4f2dbb0d031a5cab24a8cc02", "class_name": "RelatedNodeInfo"}}, "text": "4/6/24, 12:18 AM                                                  React App\n         Vinglabs Noesis Installation at ALPLA - A\n       About ALPLA                     Technical Report\n       ALPLA, otherwise     ALPLA Groupis an Austrian, international acting plastics manufacturer\n       and plastics recycler headquartered in Hard, specializing in blow-molded bottles and caps,\n       injection-molded parts, preforms and tubes. It is one of the largest producers of rigid plastic\n       packaging solutions worldwide, with a total of      177 production plantsin over          45\n       countriesworldwide, approx.        22,100 employees        and annual sales of   \u20ac 4.00 billion     in\n       2021. The annual production capacity of ALPLA\u2019s recycling companies, joint ventures and\n       collaborations amounts to approximately        203,000 tonnes of rPET          (recycled PET) and\n       74,000 tonnes of rHDPE           (recycled HDPE).ALPLA is the largest recycler of PET in\n       Europe.", "start_char_idx": 0, "end_char_idx": 1002, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "b40a4533-3bae-4625-9427-9019419569d9": {"__data__": {"id_": "b40a4533-3bae-4625-9427-9019419569d9", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5dad8c33-d152-4251-86de-d4c9e08cfc34", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "2780deadb86946032509cbf5c212e1b20a2a8fdda540831ab49d17dc2a06d303", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef4d06d7-ff96-4cb7-bc4c-7dc16e9cf395", "node_type": "1", "metadata": {}, "hash": "5b2529fa48ee56b3e618377a82dc6884a0b9f80e0a22428f63a805d42e1f6d0c", "class_name": "RelatedNodeInfo"}}, "text": "Problem Statement\n       Vinglabs was tasked to install a monitoring system at one of        ALPLA\u2019ssubsidiary       PRT(PET\n       Recycling Team)       in W\u00f6llersdorf, Austria,30km off Vienna. The system was to be\n       installed on top of a conveyor which was the input feed to the plant. The feed consisted of\n       clear PET bottles(desirable) with other plastic impurities like non-clear PET bottles, non-\n       clear PP bottles, cans, cardboards etc. The feed was traveling at a speed of        3m/s   and the\n       conveyor was    1.8m wide. PRT wanted the following analytics from the monitoring system -\n            Utilization Factor of the plant        - Fraction of time throughout the day when the\n        conveyor was empty.\n            Opaque impurity detection           - For the PRT team, opaque bottles in the input stream\n        were a big concern because even a tiny percentage could negatively affect the output.", "start_char_idx": 1010, "end_char_idx": 1950, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "ef4d06d7-ff96-4cb7-bc4c-7dc16e9cf395": {"__data__": {"id_": "ef4d06d7-ff96-4cb7-bc4c-7dc16e9cf395", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b40a4533-3bae-4625-9427-9019419569d9", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "6bdb9b31b351b92d919dace8422baaa0a09477475fb85f4fad144f2215e942f0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "40da949f-6a89-47f0-afad-30818be91c9b", "node_type": "1", "metadata": {}, "hash": "d6faedc54da136fa7daa9209692312015b8412dfe147ed87013f2ea4c3b743e8", "class_name": "RelatedNodeInfo"}}, "text": "Non food detection- As the output of the PRT recycling plant is food grade PET\n        flakes, it is imperative for them to know the amount of non food material in their input\n        stream.\n            Real time analytics      - PRT wanted to eliminate the disconnect between the office and\n        the plant floor by implementing a real time analytics system to be proactive rather than\n        reactive.\nlocalhost:3000                                                                                                 1/84/6/24, 12:18 AM                                           React App\n               0:03 / 0:04\n      The Solution - Vinglabs Noesis\n      Camera Lens selection\n      The camera lens selection was crucial as the objects were traveling at a speed of3m/sand\n      were spread on a  1.8 m wide   conveyor. Following things were to be kept in mind -\n           The images would be clicked at  extremely low exposure to avoid motion blur.\n           Capturing images atlow exposure requires a lot of illumination         as lower the\n        exposure, less light will enter the camera.", "start_char_idx": 1963, "end_char_idx": 3065, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "40da949f-6a89-47f0-afad-30818be91c9b": {"__data__": {"id_": "40da949f-6a89-47f0-afad-30818be91c9b", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef4d06d7-ff96-4cb7-bc4c-7dc16e9cf395", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "3d084d16f1492dd5198967b19d28f917364bde93e83da540635ab991db6a8995", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1cecfbfa-bd43-41c1-9ff8-a5d93f920752", "node_type": "1", "metadata": {}, "hash": "be1174482de578825e77c8133d670c61130bddb51911eb33c4ab64116417f290", "class_name": "RelatedNodeInfo"}}, "text": "The camera has to be a global shuttercamera to avoid distortion caused due to objects\n        moving at high speed.\n           The camera should have a  high pixel size   so as to incorporate as much light as\n        possible into the sensor.\nlocalhost:3000                                                                                    2/84/6/24, 12:18 AM                                                   React App\n            Increasing pixel size comes at a tradeoff to resolutionas sensor size remains\n        fixed.\n       Given these constraints, it was impossible to develop a single camera system that covers a\n       FOV of   1.8m. Thus it was decided to use       2 cameras     that would be adjacent to each other\n       capturing the left and right half of the conveyor respectively.\n       Given these variables, the constant that could be relied upon was the resolution of the\n       camera. Since it was known the minimum feature size (this is the minimum distance between\n       the features that camera lens system can resolve) to be captured was            2mm, the minimum\n       resolution of the camera was determined to be         2MP.", "start_char_idx": 3077, "end_char_idx": 4239, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "1cecfbfa-bd43-41c1-9ff8-a5d93f920752": {"__data__": {"id_": "1cecfbfa-bd43-41c1-9ff8-a5d93f920752", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "40da949f-6a89-47f0-afad-30818be91c9b", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "9fd6742f120bce9a815977725b947f74cb288c8a611976e03bccee8e45fb75ee", "class_name": "RelatedNodeInfo"}}, "text": "After carefully considering all the options, running some tests and availability constraints, it\n       was decided to go forward with-\n            2 LUCID Vision Labs Triton\u2122 TRI071S-CC, Sony IMX428, 7.1MP\n            Color Camera coupled with Fujinon CF12ZA-1S 12mm f/1.8 Machine Vision\n        C-Mount Lens. The IMX428 has a very large pixel pitch of 4.5um.\n       Lighting\n       Capturing images at a very low exposure requires a lot of lighting to capture a well lit image.", "start_char_idx": 4247, "end_char_idx": 4726, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "b43b76b8-79f9-4768-9fdc-f9b1811d000d": {"__data__": {"id_": "b43b76b8-79f9-4768-9fdc-f9b1811d000d", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b6ba581-e04a-41da-9c9c-a560fc9a5809", "node_type": "1", "metadata": {}, "hash": "52f786e80a3a659265c3eb73ac906a465b25239237a4731d71e5bad0d09d180d", "class_name": "RelatedNodeInfo"}}, "text": "4/6/24, 12:18 AM                                                  React App\n         Vinglabs Noesis Installation at ALPLA - A\n       About ALPLA                     Technical Report\n       ALPLA, otherwise     ALPLA Groupis an Austrian, international acting plastics manufacturer\n       and plastics recycler headquartered in Hard, specializing in blow-molded bottles and caps,\n       injection-molded parts, preforms and tubes. It is one of the largest producers of rigid plastic\n       packaging solutions worldwide, with a total of      177 production plantsin over          45\n       countriesworldwide, approx.        22,100 employees        and annual sales of   \u20ac 4.00 billion     in\n       2021. The annual production capacity of ALPLA\u2019s recycling companies, joint ventures and\n       collaborations amounts to approximately        203,000 tonnes of rPET          (recycled PET) and\n       74,000 tonnes of rHDPE           (recycled HDPE).ALPLA is the largest recycler of PET in\n       Europe.\n       Problem Statement\n       Vinglabs was tasked to install a monitoring system at one of        ALPLA\u2019ssubsidiary       PRT(PET\n       Recycling Team)       in W\u00f6llersdorf, Austria,30km off Vienna. The system was to be\n       installed on top of a conveyor which was the input feed to the plant. The feed consisted of\n       clear PET bottles(desirable) with other plastic impurities like non-clear PET bottles, non-\n       clear PP bottles, cans, cardboards etc. The feed was traveling at a speed of        3m/s   and the\n       conveyor was    1.8m wide. PRT wanted the following analytics from the monitoring system -\n            Utilization Factor of the plant        - Fraction of time throughout the day when the\n        conveyor was empty.\n            Opaque impurity detection           - For the PRT team, opaque bottles in the input stream\n        were a big concern because even a tiny percentage could negatively affect the output.\n            Non food detection- As the output of the PRT recycling plant is food grade PET\n        flakes, it is imperative for them to know the amount of non food material in their input\n        stream.", "start_char_idx": 0, "end_char_idx": 2154, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "1b6ba581-e04a-41da-9c9c-a560fc9a5809": {"__data__": {"id_": "1b6ba581-e04a-41da-9c9c-a560fc9a5809", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b43b76b8-79f9-4768-9fdc-f9b1811d000d", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "d4cd3819dc28b2d695a39f1adff347fb424e79d748e40aa774d852dab23adf1c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b78c7981-a043-4911-9d8e-2af26d86f47b", "node_type": "1", "metadata": {}, "hash": "9ad3812423762279e5d90750d23aa51694b339faca125db29c63999fab579797", "class_name": "RelatedNodeInfo"}}, "text": "Real time analytics      - PRT wanted to eliminate the disconnect between the office and\n        the plant floor by implementing a real time analytics system to be proactive rather than\n        reactive.\nlocalhost:3000                                                                                                 1/84/6/24, 12:18 AM                                           React App\n               0:03 / 0:04\n      The Solution - Vinglabs Noesis\n      Camera Lens selection\n      The camera lens selection was crucial as the objects were traveling at a speed of3m/sand\n      were spread on a  1.8 m wide   conveyor. Following things were to be kept in mind -\n           The images would be clicked at  extremely low exposure to avoid motion blur.\n           Capturing images atlow exposure requires a lot of illumination         as lower the\n        exposure, less light will enter the camera.\n           The camera has to be a global shuttercamera to avoid distortion caused due to objects\n        moving at high speed.\n           The camera should have a  high pixel size   so as to incorporate as much light as\n        possible into the sensor.\nlocalhost:3000                                                                                    2/84/6/24, 12:18 AM                                                   React App\n            Increasing pixel size comes at a tradeoff to resolutionas sensor size remains\n        fixed.\n       Given these constraints, it was impossible to develop a single camera system that covers a\n       FOV of   1.8m. Thus it was decided to use       2 cameras     that would be adjacent to each other\n       capturing the left and right half of the conveyor respectively.\n       Given these variables, the constant that could be relied upon was the resolution of the\n       camera. Since it was known the minimum feature size (this is the minimum distance between\n       the features that camera lens system can resolve) to be captured was            2mm, the minimum\n       resolution of the camera was determined to be         2MP.\n       After carefully considering all the options, running some tests and availability constraints, it\n       was decided to go forward with-\n            2 LUCID Vision Labs Triton\u2122 TRI071S-CC, Sony IMX428, 7.1MP\n            Color Camera coupled with Fujinon CF12ZA-1S 12mm f/1.8 Machine Vision\n        C-Mount Lens.", "start_char_idx": 2167, "end_char_idx": 4557, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "b78c7981-a043-4911-9d8e-2af26d86f47b": {"__data__": {"id_": "b78c7981-a043-4911-9d8e-2af26d86f47b", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b6ba581-e04a-41da-9c9c-a560fc9a5809", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "bde79e5711dfe8a26f28c33b3dd3a252cafb289c18ced03ba1af893acc23b6b1", "class_name": "RelatedNodeInfo"}}, "text": "The IMX428 has a very large pixel pitch of 4.5um.\n       Lighting\n       Capturing images at a very low exposure requires a lot of lighting to capture a well lit image.", "start_char_idx": 4558, "end_char_idx": 4726, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-0": {"__data__": {"id_": "node-0", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aeaf2ba9-3618-4a99-898b-4bd941cd1a70", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "673799bad9e81eec076fb725ca6633fec63dceb2b3e4541ff40dadea5cc2169f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "db31e950-bb5d-405f-a57f-3272b7e79d04", "node_type": "1", "metadata": {}, "hash": "fa157cc11751eca829b27cb087fcb5161544f3ad14388cffedce081f4566ec63", "class_name": "RelatedNodeInfo"}}, "text": "4/6/24, 12:18 AM                                                  React App\n         Vinglabs Noesis Installation at ALPLA - A\n       About ALPLA                     Technical Report\n       ALPLA, otherwise     ALPLA Groupis an Austrian, international acting plastics manufacturer\n       and plastics recycler headquartered in Hard, specializing in blow-molded bottles and caps,\n       injection-molded parts, preforms and tubes. It is one of the largest producers of rigid plastic\n       packaging solutions worldwide, with a total of      177 production plantsin over          45\n       countriesworldwide, approx.        22,100 employees        and annual sales of   \u20ac 4.00 billion     in\n       2021. The annual production capacity of ALPLA\u2019s recycling companies, joint ventures and\n       collaborations amounts to approximately        203,000 tonnes of rPET          (recycled PET) and\n       74,000 tonnes of rHDPE           (recycled HDPE).ALPLA is the largest recycler of PET in\n       Europe.\n       Problem Statement\n       Vinglabs was tasked to install a monitoring system at one of        ALPLA\u2019ssubsidiary       PRT(PET\n       Recycling Team)       in W\u00f6llersdorf, Austria,30km off Vienna. The system was to be\n       installed on top of a conveyor which was the input feed to the plant. The feed consisted of\n       clear PET bottles(desirable) with other plastic impurities like non-clear PET bottles, non-\n       clear PP bottles, cans, cardboards etc. The feed was traveling at a speed of        3m/s   and the\n       conveyor was    1.8m wide. PRT wanted the following analytics from the monitoring system -\n            Utilization Factor of the plant        - Fraction of time throughout the day when the\n        conveyor was empty.\n            Opaque impurity detection           - For the PRT team, opaque bottles in the input stream\n        were a big concern because even a tiny percentage could negatively affect the output.\n            Non food detection- As the output of the PRT recycling plant is food grade PET\n        flakes, it is imperative for them to know the amount of non food material in their input\n        stream.\n            Real time analytics      - PRT wanted to eliminate the disconnect between the office and\n        the plant floor by implementing a real time analytics system to be proactive rather than\n        reactive.\nlocalhost:3000                                                                                                 1/84/6/24, 12:18 AM                                           React App\n               0:03 / 0:04\n      The Solution - Vinglabs Noesis\n      Camera Lens selection\n      The camera lens selection was crucial as the objects were traveling at a speed of3m/sand\n      were spread on a  1.8 m wide   conveyor. Following things were to be kept in mind -\n           The images would be clicked at  extremely low exposure to avoid motion blur.\n           Capturing images atlow exposure requires a lot of illumination         as lower the\n        exposure, less light will enter the camera.\n           The camera has to be a global shuttercamera to avoid distortion caused due to objects\n        moving at high speed.\n           The camera should have a  high pixel size   so as to incorporate as much light as\n        possible into the sensor.\nlocalhost:3000                                                                                    2/84/6/24, 12:18 AM                                                   React App\n            Increasing pixel size comes at a tradeoff to resolutionas sensor size remains\n        fixed.\n       Given these constraints, it was impossible to develop a single camera system that covers a\n       FOV of   1.8m. Thus it was decided to use       2 cameras     that would be adjacent to each other\n       capturing the left and right half of the conveyor respectively.\n       Given these variables, the constant that could be relied upon was the resolution of the\n       camera. Since it was known the minimum feature size (this is the minimum distance between\n       the features that camera lens system can resolve) to be captured was            2mm, the minimum\n       resolution of the camera was determined to be         2MP.\n       After carefully considering all the options, running some tests and availability constraints, it\n       was decided to go forward with-\n            2 LUCID Vision Labs Triton\u2122 TRI071S-CC, Sony IMX428, 7.1MP\n            Color Camera coupled with Fujinon CF12ZA-1S 12mm f/1.8 Machine Vision\n        C-Mount Lens. The IMX428 has a very large pixel pitch of 4.5um.\n       Lighting\n       Capturing images at a very low exposure requires a lot of lighting to capture a well lit image.", "start_char_idx": 0, "end_char_idx": 4726, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "e4e7f5fb-6fc1-413e-8013-b0ab34aaa477": {"__data__": {"id_": "e4e7f5fb-6fc1-413e-8013-b0ab34aaa477", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3fdb0b6f-13b0-45f2-8d7d-92673c9e9f45", "node_type": "1", "metadata": {}, "hash": "d7ea08f4571fadcc3b41c1babe3aadb955f0ad8e0acd8173cf1941740a990ab9", "class_name": "RelatedNodeInfo"}}, "text": "We used diffused rectangular LED light panels with a target lux of 10,000 on the surface of\n       the conveyor.\n       System design of ML pipeline\n       The ML pipeline consisted of following parts -\n                         Data Collection Data Labelling   Model Training  Error Analysis Model Deployment\n       Data Collection\n            In a fully operational plant, it is imperative to capture diverse data at different times\n        throughout the day as capturing data only during particular hours may lead to the\n        collection of a particular kind of data and thus lead to poor classifiers. Also, one cannot\n        collect all the data as it would be impossible to manage such huge amounts of data.\nlocalhost:3000                                                                                             3/84/6/24, 12:18 AM                                                 React App\n            We decided to collect a burst of   1000 images every 30 minutes             throughout the day.\n        The data would be saved to externally connected Solid State Drives and would be uploaded\n        automatically to cloud(S3) whenever the images are not being clicked.", "start_char_idx": 0, "end_char_idx": 1183, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "3fdb0b6f-13b0-45f2-8d7d-92673c9e9f45": {"__data__": {"id_": "3fdb0b6f-13b0-45f2-8d7d-92673c9e9f45", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e4e7f5fb-6fc1-413e-8013-b0ab34aaa477", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "a9b4fe4f755b14b418d9ae46fb60759be8f1274e80c0837edc2b5878973c65d2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f08b1c79-4da9-4eee-8d75-6377cc1fc47a", "node_type": "1", "metadata": {}, "hash": "bc02e4006bc68c1cd49dafeca88493d61cc57cdfdab1ff12c7ebfa947085be77", "class_name": "RelatedNodeInfo"}}, "text": "To click and save images, a typical   multithreaded master-slave architecture was\n        used with a queue in between.           One thread was responsible for clicking images and\n        dumping into the queue and multiple threads were used for popping the queue and saving\n        the image to disk.\n       Splitting up the problem into multiple parts with multiple classifiers\n       There are two ways to solve a complex ML problem.\n            The first is totrain an end to end modelwhich takes in the captured images, does\n        the object detection and classification(of type of object,color and food/non food) in one\n        shot.\n            The other way is to  split the problem into multiple sub problems and sub\n        classifiers and combine the result. This is always preferable as-\n          1. It helps us track the real performance bottleneck of our pipeline thereby giving us a\n          targeted approach to solve the problem.\n          2. Smaller classifiers are easier to debug and run through the machine learning loop.", "start_char_idx": 1196, "end_char_idx": 2243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "f08b1c79-4da9-4eee-8d75-6377cc1fc47a": {"__data__": {"id_": "f08b1c79-4da9-4eee-8d75-6377cc1fc47a", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3fdb0b6f-13b0-45f2-8d7d-92673c9e9f45", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "221ecd3376f86b40ff1a5366fb441cd123671f723d8f7b842d01ab9d3c63633d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "741df109-64d7-4014-978f-ff683a874623", "node_type": "1", "metadata": {}, "hash": "320508d0d95e9f2deeca67736e169e5f792b4b5caea7cbfa2423686f1dd0323e", "class_name": "RelatedNodeInfo"}}, "text": "We split the problem into multiple classifiers as per the following flowchart -\nlocalhost:3000                                                                                               4/84/6/24, 12:18 AM             VINGLABS             PET RECYCLING  React App\n                            TECHNOLOGIES          TEAMAMombor of tho ALPLA Group\n                                                       Object\n                                                      Detection\n                                                       Bottle\n                                                      Classifier\n                                              No Bottle           Bottle\n                                       No Boltle                          CCior\n                                       Classifief                        Classilien\n                                                      Clear-Light Blue Gsreen Oiher\n                                                       FoNan\n                                                        Classilier\n                                                  Food Grade Non Font\n                                       PRT CLASSIFICATION CATEGORIES FOR LABELLING\n       The problem was split up into 1 object detection model, and 3 classifiers-\n            Object Detection      - YOLO and YOLO-like family of models\n            Bottle/Cans/Other Classifier          - Resnet, GoogleNet, Squeezenet, ShuffleNet,\n        EfficientNet family of models\n            Color(Clear,Light Blue/Brown/Green/Black/Opaque/Other) Classifier                           -\n        Specially designed models of classification family to deal with colors.", "start_char_idx": 2251, "end_char_idx": 3926, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "741df109-64d7-4014-978f-ff683a874623": {"__data__": {"id_": "741df109-64d7-4014-978f-ff683a874623", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f08b1c79-4da9-4eee-8d75-6377cc1fc47a", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4ff3bbd107c1ea457fa4076338d566f183657d76444b8fb215ad54c606a6fc21", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c0aee3bd-fe39-45b9-b4e3-3f716f6a9cf5", "node_type": "1", "metadata": {}, "hash": "5571b767688ec3501dbaeb9dc3198d002b3f3992eef8a51514aaf8a41c1b962d", "class_name": "RelatedNodeInfo"}}, "text": "Food/Non Food Classifier- We used many visual markers like shape of the bottle,\n        transparency, brands etc. to detect non food bottles in input stream. A combination of\n        YOLO styled and classification styled model.\n       In the final deployment of models, the object detection model needed to process           8 images\n       and the  3 classifiers   needed to process    100 objects each, all in     1 sec.\n       Label - Train - Error Analysis loop\n       We extensively used    active learning     along with a team of multiple human labellers to label\n       millions of images in a short amount of time. Following tools were used throughout this loop\n       -    Pytorch   - To write models,training loops,data loaders etc.\n            Wandb     - To track models, dataset and training.\n            S3 - As object store.\n            Apache Airflow      - To orchestrate ETL pipelines involved in preprocessing.\n            Kubernetes- To scale across different nodes for tuning hyperparameters.", "start_char_idx": 3939, "end_char_idx": 4953, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "c0aee3bd-fe39-45b9-b4e3-3f716f6a9cf5": {"__data__": {"id_": "c0aee3bd-fe39-45b9-b4e3-3f716f6a9cf5", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "741df109-64d7-4014-978f-ff683a874623", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "a384683e68cf59351869a34b0da11e0e50edc596d87423a3160a8b757613e22b", "class_name": "RelatedNodeInfo"}}, "text": "localhost:3000                                                                                             5/84/6/24, 12:18 AM                                      Baseline   React App\n                                                     Model/Trained\n                               Preprocessing           Model            Manual Labelling\n                                EB         OPMrch  aw3        Au        Model Training\n       Model Deployment                              Error Analysis\n       All the models were deployed locally on an      AGX JETSON ORIN           with the stream of images\n       and models connected with a lightweight       RabbitMQ. This enabled objects being retained\n       even if there was a hit on execution speed of models.", "start_char_idx": 4954, "end_char_idx": 5716, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "8e29643f-d92a-444e-8ae4-9a91366f7892": {"__data__": {"id_": "8e29643f-d92a-444e-8ae4-9a91366f7892", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6608ad4d-3e2c-4d2a-8d77-051d29bad800", "node_type": "1", "metadata": {}, "hash": "c9ef2dd5a73c6efbd69ad872637c7a8b5311c3bfad8e0eebbb61d17f9305eaa0", "class_name": "RelatedNodeInfo"}}, "text": "We used diffused rectangular LED light panels with a target lux of 10,000 on the surface of\n       the conveyor.\n       System design of ML pipeline\n       The ML pipeline consisted of following parts -\n                         Data Collection Data Labelling   Model Training  Error Analysis Model Deployment\n       Data Collection\n            In a fully operational plant, it is imperative to capture diverse data at different times\n        throughout the day as capturing data only during particular hours may lead to the\n        collection of a particular kind of data and thus lead to poor classifiers. Also, one cannot\n        collect all the data as it would be impossible to manage such huge amounts of data.\nlocalhost:3000                                                                                             3/84/6/24, 12:18 AM                                                 React App\n            We decided to collect a burst of   1000 images every 30 minutes             throughout the day.\n        The data would be saved to externally connected Solid State Drives and would be uploaded\n        automatically to cloud(S3) whenever the images are not being clicked.\n            To click and save images, a typical   multithreaded master-slave architecture was\n        used with a queue in between.           One thread was responsible for clicking images and\n        dumping into the queue and multiple threads were used for popping the queue and saving\n        the image to disk.\n       Splitting up the problem into multiple parts with multiple classifiers\n       There are two ways to solve a complex ML problem.\n            The first is totrain an end to end modelwhich takes in the captured images, does\n        the object detection and classification(of type of object,color and food/non food) in one\n        shot.\n            The other way is to  split the problem into multiple sub problems and sub\n        classifiers and combine the result. This is always preferable as-\n          1. It helps us track the real performance bottleneck of our pipeline thereby giving us a\n          targeted approach to solve the problem.\n          2. Smaller classifiers are easier to debug and run through the machine learning loop.", "start_char_idx": 0, "end_char_idx": 2243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "6608ad4d-3e2c-4d2a-8d77-051d29bad800": {"__data__": {"id_": "6608ad4d-3e2c-4d2a-8d77-051d29bad800", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8e29643f-d92a-444e-8ae4-9a91366f7892", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "11e8a3abc6e1507ede7c2542a6e3e987459e03b5c61610eb3d6d1e478be6e35e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "078c9d85-5279-41f2-95f0-c54582a0dce8", "node_type": "1", "metadata": {}, "hash": "5571b767688ec3501dbaeb9dc3198d002b3f3992eef8a51514aaf8a41c1b962d", "class_name": "RelatedNodeInfo"}}, "text": "We split the problem into multiple classifiers as per the following flowchart -\nlocalhost:3000                                                                                               4/84/6/24, 12:18 AM             VINGLABS             PET RECYCLING  React App\n                            TECHNOLOGIES          TEAMAMombor of tho ALPLA Group\n                                                       Object\n                                                      Detection\n                                                       Bottle\n                                                      Classifier\n                                              No Bottle           Bottle\n                                       No Boltle                          CCior\n                                       Classifief                        Classilien\n                                                      Clear-Light Blue Gsreen Oiher\n                                                       FoNan\n                                                        Classilier\n                                                  Food Grade Non Font\n                                       PRT CLASSIFICATION CATEGORIES FOR LABELLING\n       The problem was split up into 1 object detection model, and 3 classifiers-\n            Object Detection      - YOLO and YOLO-like family of models\n            Bottle/Cans/Other Classifier          - Resnet, GoogleNet, Squeezenet, ShuffleNet,\n        EfficientNet family of models\n            Color(Clear,Light Blue/Brown/Green/Black/Opaque/Other) Classifier                           -\n        Specially designed models of classification family to deal with colors.\n            Food/Non Food Classifier- We used many visual markers like shape of the bottle,\n        transparency, brands etc. to detect non food bottles in input stream. A combination of\n        YOLO styled and classification styled model.\n       In the final deployment of models, the object detection model needed to process           8 images\n       and the  3 classifiers   needed to process    100 objects each, all in     1 sec.\n       Label - Train - Error Analysis loop\n       We extensively used    active learning     along with a team of multiple human labellers to label\n       millions of images in a short amount of time. Following tools were used throughout this loop\n       -    Pytorch   - To write models,training loops,data loaders etc.\n            Wandb     - To track models, dataset and training.\n            S3 - As object store.\n            Apache Airflow      - To orchestrate ETL pipelines involved in preprocessing.\n            Kubernetes- To scale across different nodes for tuning hyperparameters.", "start_char_idx": 2251, "end_char_idx": 4953, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "078c9d85-5279-41f2-95f0-c54582a0dce8": {"__data__": {"id_": "078c9d85-5279-41f2-95f0-c54582a0dce8", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6608ad4d-3e2c-4d2a-8d77-051d29bad800", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "553da9a602907d109c17152481d5c71fcfdd641b76691a1d4d8af918c4ef4cdb", "class_name": "RelatedNodeInfo"}}, "text": "localhost:3000                                                                                             5/84/6/24, 12:18 AM                                      Baseline   React App\n                                                     Model/Trained\n                               Preprocessing           Model            Manual Labelling\n                                EB         OPMrch  aw3        Au        Model Training\n       Model Deployment                              Error Analysis\n       All the models were deployed locally on an      AGX JETSON ORIN           with the stream of images\n       and models connected with a lightweight       RabbitMQ. This enabled objects being retained\n       even if there was a hit on execution speed of models.", "start_char_idx": 4954, "end_char_idx": 5716, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-1": {"__data__": {"id_": "node-1", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aeaf2ba9-3618-4a99-898b-4bd941cd1a70", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "673799bad9e81eec076fb725ca6633fec63dceb2b3e4541ff40dadea5cc2169f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c140f027-8355-47d2-b73d-a3b39726b74c", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f7db84bb-1454-454b-aabc-ad48a0f15efb", "node_type": "1", "metadata": {}, "hash": "39a865198bf078df443295244c5a02c907e7352b8c982988f8d6f42efefae530", "class_name": "RelatedNodeInfo"}}, "text": "We used diffused rectangular LED light panels with a target lux of 10,000 on the surface of\n       the conveyor.\n       System design of ML pipeline\n       The ML pipeline consisted of following parts -\n                         Data Collection Data Labelling   Model Training  Error Analysis Model Deployment\n       Data Collection\n            In a fully operational plant, it is imperative to capture diverse data at different times\n        throughout the day as capturing data only during particular hours may lead to the\n        collection of a particular kind of data and thus lead to poor classifiers. Also, one cannot\n        collect all the data as it would be impossible to manage such huge amounts of data.\nlocalhost:3000                                                                                             3/84/6/24, 12:18 AM                                                 React App\n            We decided to collect a burst of   1000 images every 30 minutes             throughout the day.\n        The data would be saved to externally connected Solid State Drives and would be uploaded\n        automatically to cloud(S3) whenever the images are not being clicked.\n            To click and save images, a typical   multithreaded master-slave architecture was\n        used with a queue in between.           One thread was responsible for clicking images and\n        dumping into the queue and multiple threads were used for popping the queue and saving\n        the image to disk.\n       Splitting up the problem into multiple parts with multiple classifiers\n       There are two ways to solve a complex ML problem.\n            The first is totrain an end to end modelwhich takes in the captured images, does\n        the object detection and classification(of type of object,color and food/non food) in one\n        shot.\n            The other way is to  split the problem into multiple sub problems and sub\n        classifiers and combine the result. This is always preferable as-\n          1. It helps us track the real performance bottleneck of our pipeline thereby giving us a\n          targeted approach to solve the problem.\n          2. Smaller classifiers are easier to debug and run through the machine learning loop.\n       We split the problem into multiple classifiers as per the following flowchart -\nlocalhost:3000                                                                                               4/84/6/24, 12:18 AM             VINGLABS             PET RECYCLING  React App\n                            TECHNOLOGIES          TEAMAMombor of tho ALPLA Group\n                                                       Object\n                                                      Detection\n                                                       Bottle\n                                                      Classifier\n                                              No Bottle           Bottle\n                                       No Boltle                          CCior\n                                       Classifief                        Classilien\n                                                      Clear-Light Blue Gsreen Oiher\n                                                       FoNan\n                                                        Classilier\n                                                  Food Grade Non Font\n                                       PRT CLASSIFICATION CATEGORIES FOR LABELLING\n       The problem was split up into 1 object detection model, and 3 classifiers-\n            Object Detection      - YOLO and YOLO-like family of models\n            Bottle/Cans/Other Classifier          - Resnet, GoogleNet, Squeezenet, ShuffleNet,\n        EfficientNet family of models\n            Color(Clear,Light Blue/Brown/Green/Black/Opaque/Other) Classifier                           -\n        Specially designed models of classification family to deal with colors.\n            Food/Non Food Classifier- We used many visual markers like shape of the bottle,\n        transparency, brands etc. to detect non food bottles in input stream. A combination of\n        YOLO styled and classification styled model.\n       In the final deployment of models, the object detection model needed to process           8 images\n       and the  3 classifiers   needed to process    100 objects each, all in     1 sec.\n       Label - Train - Error Analysis loop\n       We extensively used    active learning     along with a team of multiple human labellers to label\n       millions of images in a short amount of time. Following tools were used throughout this loop\n       -    Pytorch   - To write models,training loops,data loaders etc.\n            Wandb     - To track models, dataset and training.\n            S3 - As object store.\n            Apache Airflow      - To orchestrate ETL pipelines involved in preprocessing.\n            Kubernetes- To scale across different nodes for tuning hyperparameters.\nlocalhost:3000                                                                                             5/84/6/24, 12:18 AM                                      Baseline   React App\n                                                     Model/Trained\n                               Preprocessing           Model            Manual Labelling\n                                EB         OPMrch  aw3        Au        Model Training\n       Model Deployment                              Error Analysis\n       All the models were deployed locally on an      AGX JETSON ORIN           with the stream of images\n       and models connected with a lightweight       RabbitMQ. This enabled objects being retained\n       even if there was a hit on execution speed of models.", "start_char_idx": 4734, "end_char_idx": 10450, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "5f72e838-dff6-464b-81e6-32b7702d5457": {"__data__": {"id_": "5f72e838-dff6-464b-81e6-32b7702d5457", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "471c068b-1bb1-4183-b3f5-423e399d32c6", "node_type": "1", "metadata": {}, "hash": "49758b30e7d6de8105a71774e50542a9bd718675ff9333f11f492a14711053c8", "class_name": "RelatedNodeInfo"}}, "text": "We were able to consistently clock\n       800ms for inference 8 images/sec             end to end which involved running multiple\n       classifiers on 100 images/sec.\n       The Impact\n       Pet Recycling Team (PRT), a subsidiary of           ALPLA, is a PET recycler in Europe.\n       Vinglabs    installed their system at PRT W\u00f6llersdorf, Austria on       October 1st 2022. Through\n       real-time monitoring using Vinglabs proprietary AI        Noesis   and a highly interactive\n       dashboard   Athena, the installation achieved the following goals successfully -\n            Utilization factor of plant      - Through Noesis\u2019s real time bottle detection, it is now\n        possible for stakeholders to monitor the plant throughput in real time, thus enabling them\n        to detect the least productive times of the day to take corrective action.", "start_char_idx": 0, "end_char_idx": 856, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "471c068b-1bb1-4183-b3f5-423e399d32c6": {"__data__": {"id_": "471c068b-1bb1-4183-b3f5-423e399d32c6", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f72e838-dff6-464b-81e6-32b7702d5457", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "87668f8da7d051aa9022d0a181f7bf298032a6a0c21c2b9904d5a749798594ed", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad2c688e-f8a2-42a9-b107-65b95b04bd59", "node_type": "1", "metadata": {}, "hash": "30a82def77076992da7259aa809d278a58d39d4022fbdf9a7d0dc5d9b36fe34f", "class_name": "RelatedNodeInfo"}}, "text": "Bottle            Others           Cans\n            Opaque impurity detection          - For PRT team, opaque bottles in input stream were a\n        big concern because even a tiny percentage could negatively affect the output.Through\n        Noesis\u2019s real time color detection, PRT is able to monitor and get notified about opaque\nlocalhost:3000                                                                                              6/84/6/24, 12:18 AM                                              React App\n       percentage in input stream.Along with opaque bottle detection Noesis also detects bottles\n       of different colors like green,blue etc. to give real time insights to the plant.\n                       Clear     Clear Sleeved  Green        Opaque      Others       Blue\n           Non food detection- As the output of PRT recycling plant is food grade PET flakes, it\n       is imperative for them to know the amount of non food material in their input stream.\n       Noesis uses many visual markers like shape of the bottle, transparency, brands etc. to\n       detect non food bottles in input stream.", "start_char_idx": 897, "end_char_idx": 2020, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "ad2c688e-f8a2-42a9-b107-65b95b04bd59": {"__data__": {"id_": "ad2c688e-f8a2-42a9-b107-65b95b04bd59", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "471c068b-1bb1-4183-b3f5-423e399d32c6", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "2b980ee500b8e2cb2698952bbbd698bdabbd675f32a9a8101fe06a15cc0b53f0", "class_name": "RelatedNodeInfo"}}, "text": "Food               Non-Food\n           Visualizing analytics on Athena        - To visualize all the analytics and insights,\n       Vinglabs has provided PRT with a highly interactive dashboard \u201cAthena\u201d which gives them\n       live as well as historical view of insights generated by Noesis.\n              VINCLABS                        Plant Analytics  VINCLABS                        Plant Analytics\n              Icuaa?                        4574                                             4\n                                                                           LAAA\n              Throughput Analytics on Athena                       Color Analytics on Athena\n                                       VINCLABS                        Plant Analytics\n                                                                    41.,7J\nlocalhost:3000                                                                                                 7/84/6/24, 12:18 AM        React App\n               Food/Non food Analytics on Athena\nlocalhost:3000                            8/8", "start_char_idx": 2065, "end_char_idx": 3140, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "02baf39f-64cd-43fb-b364-07660debf40b": {"__data__": {"id_": "02baf39f-64cd-43fb-b364-07660debf40b", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2b9551d2-6ebf-47e8-8a76-1cef93313552", "node_type": "1", "metadata": {}, "hash": "f00b907de6756817f55cd0b4e348da50aff8c34fbbba4f48bf74fbf917fc6086", "class_name": "RelatedNodeInfo"}}, "text": "We were able to consistently clock\n       800ms for inference 8 images/sec             end to end which involved running multiple\n       classifiers on 100 images/sec.\n       The Impact\n       Pet Recycling Team (PRT), a subsidiary of           ALPLA, is a PET recycler in Europe.\n       Vinglabs    installed their system at PRT W\u00f6llersdorf, Austria on       October 1st 2022. Through\n       real-time monitoring using Vinglabs proprietary AI        Noesis   and a highly interactive\n       dashboard   Athena, the installation achieved the following goals successfully -\n            Utilization factor of plant      - Through Noesis\u2019s real time bottle detection, it is now\n        possible for stakeholders to monitor the plant throughput in real time, thus enabling them\n        to detect the least productive times of the day to take corrective action.\n                                        Bottle            Others           Cans\n            Opaque impurity detection          - For PRT team, opaque bottles in input stream were a\n        big concern because even a tiny percentage could negatively affect the output.Through\n        Noesis\u2019s real time color detection, PRT is able to monitor and get notified about opaque\nlocalhost:3000                                                                                              6/84/6/24, 12:18 AM                                              React App\n       percentage in input stream.Along with opaque bottle detection Noesis also detects bottles\n       of different colors like green,blue etc. to give real time insights to the plant.\n                       Clear     Clear Sleeved  Green        Opaque      Others       Blue\n           Non food detection- As the output of PRT recycling plant is food grade PET flakes, it\n       is imperative for them to know the amount of non food material in their input stream.\n       Noesis uses many visual markers like shape of the bottle, transparency, brands etc. to\n       detect non food bottles in input stream.\n                                            Food               Non-Food\n           Visualizing analytics on Athena        - To visualize all the analytics and insights,\n       Vinglabs has provided PRT with a highly interactive dashboard \u201cAthena\u201d which gives them\n       live as well as historical view of insights generated by Noesis.\n              VINCLABS                        Plant Analytics  VINCLABS                        Plant Analytics\n              Icuaa?", "start_char_idx": 0, "end_char_idx": 2488, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "2b9551d2-6ebf-47e8-8a76-1cef93313552": {"__data__": {"id_": "2b9551d2-6ebf-47e8-8a76-1cef93313552", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "02baf39f-64cd-43fb-b364-07660debf40b", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "e59099822145a249f4052a777b945b2671e327c0944efb3790a3dd7b2aab2368", "class_name": "RelatedNodeInfo"}}, "text": "4574                                             4\n                                                                           LAAA\n              Throughput Analytics on Athena                       Color Analytics on Athena\n                                       VINCLABS                        Plant Analytics\n                                                                    41.,7J\nlocalhost:3000                                                                                                 7/84/6/24, 12:18 AM        React App\n               Food/Non food Analytics on Athena\nlocalhost:3000                            8/8", "start_char_idx": 2512, "end_char_idx": 3140, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-2": {"__data__": {"id_": "node-2", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aeaf2ba9-3618-4a99-898b-4bd941cd1a70", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "673799bad9e81eec076fb725ca6633fec63dceb2b3e4541ff40dadea5cc2169f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "db31e950-bb5d-405f-a57f-3272b7e79d04", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}}, "text": "We were able to consistently clock\n       800ms for inference 8 images/sec             end to end which involved running multiple\n       classifiers on 100 images/sec.\n       The Impact\n       Pet Recycling Team (PRT), a subsidiary of           ALPLA, is a PET recycler in Europe.\n       Vinglabs    installed their system at PRT W\u00f6llersdorf, Austria on       October 1st 2022. Through\n       real-time monitoring using Vinglabs proprietary AI        Noesis   and a highly interactive\n       dashboard   Athena, the installation achieved the following goals successfully -\n            Utilization factor of plant      - Through Noesis\u2019s real time bottle detection, it is now\n        possible for stakeholders to monitor the plant throughput in real time, thus enabling them\n        to detect the least productive times of the day to take corrective action.\n                                        Bottle            Others           Cans\n            Opaque impurity detection          - For PRT team, opaque bottles in input stream were a\n        big concern because even a tiny percentage could negatively affect the output.Through\n        Noesis\u2019s real time color detection, PRT is able to monitor and get notified about opaque\nlocalhost:3000                                                                                              6/84/6/24, 12:18 AM                                              React App\n       percentage in input stream.Along with opaque bottle detection Noesis also detects bottles\n       of different colors like green,blue etc. to give real time insights to the plant.\n                       Clear     Clear Sleeved  Green        Opaque      Others       Blue\n           Non food detection- As the output of PRT recycling plant is food grade PET flakes, it\n       is imperative for them to know the amount of non food material in their input stream.\n       Noesis uses many visual markers like shape of the bottle, transparency, brands etc. to\n       detect non food bottles in input stream.\n                                            Food               Non-Food\n           Visualizing analytics on Athena        - To visualize all the analytics and insights,\n       Vinglabs has provided PRT with a highly interactive dashboard \u201cAthena\u201d which gives them\n       live as well as historical view of insights generated by Noesis.\n              VINCLABS                        Plant Analytics  VINCLABS                        Plant Analytics\n              Icuaa?                        4574                                             4\n                                                                           LAAA\n              Throughput Analytics on Athena                       Color Analytics on Athena\n                                       VINCLABS                        Plant Analytics\n                                                                    41.,7J\nlocalhost:3000                                                                                                 7/84/6/24, 12:18 AM        React App\n               Food/Non food Analytics on Athena\nlocalhost:3000                            8/8", "start_char_idx": 10451, "end_char_idx": 13591, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "adf083e2-9d2e-4a57-ae26-8ea181edad1d": {"__data__": {"id_": "adf083e2-9d2e-4a57-ae26-8ea181edad1d", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p1_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to the technical considerations involved in selecting an appropriate camera lens for capturing images of objects moving at a significant speed on a conveyor belt. The objects in question are moving at a velocity of 3 meters per second and are distributed across a conveyor that is 1.8 meters in width. To ensure clarity and sharpness in the captured images, the exposure time must be very short, which helps in reducing motion blur. However, such low exposure times necessitate additional illumination since less light is able to reach the camera's sensor under these conditions.\n\nMoreover, the camera in use must be equipped with a global shutter mechanism. This is essential to prevent any distortion in the images that could be caused by the high-speed movement of the objects. A global shutter captures the entire image simultaneously, as opposed to a rolling shutter which captures the image in a sequential manner, potentially leading to distortion.\n\nLastly, the camera should possess a sensor with a high pixel size. Larger pixels are capable of capturing more light, which is particularly beneficial when dealing with low exposure photography. This is because larger pixels have a greater surface area to collect light, making them more efficient in low-light conditions. All these factors combined ensure that the images of the objects on the conveyor are captured with precision and clarity, despite the challenging conditions presented by their rapid movement.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4a796597-b7c8-44fe-87c4-bb32511e611a": {"__data__": {"id_": "4a796597-b7c8-44fe-87c4-bb32511e611a", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p1_2"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The setup in question involves a sophisticated piece of equipment designed to capture high-speed objects on a conveyor system. The equipment is engineered to handle objects moving at a velocity of 3 meters per second across a conveyor that is 1.8 meters wide. To achieve the necessary image clarity at such speeds, the system employs a camera with a specialized lens that can take pictures at very low exposure times. This is to ensure that motion blur is minimized, allowing for crisp, clear images of the objects in motion.\n\nTo compensate for the low exposure, which allows less light to reach the camera sensor, the system requires ample illumination. This is critical because the lower the exposure, the greater the need for external light sources to properly illuminate the objects being photographed. Additionally, the camera is equipped with a global shutter mechanism. This is an important feature because it captures the entire image simultaneously, which is essential for avoiding the distortion that can occur when imaging fast-moving objects with a rolling shutter camera.\n\nFurthermore, the camera sensor has a high pixel size. This characteristic is vital because larger pixels can capture more light, which is particularly beneficial when operating at low exposure levels. This combination of a global shutter and high pixel size ensures that the camera can effectively capture detailed images of objects as they move rapidly across the conveyor, even under challenging lighting conditions. The system is a testament to the careful consideration of the technical requirements necessary for high-speed photography in an industrial setting.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "97cd8e28-9897-40d4-b554-e4abc03c0be4": {"__data__": {"id_": "97cd8e28-9897-40d4-b554-e4abc03c0be4", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p2_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The content you provided discusses a camera system designed for capturing images in an industrial setting, specifically mentioning a conveyor where the field of view (FOV) is 1.8 meters wide. To accommodate this, two high-resolution cameras from LUCID Vision Labs, each with a 7.1-megapixel sensor and a large pixel pitch, are used side by side to capture the entire width of the conveyor. These cameras are paired with Fujinon lenses to ensure clarity and detail in the captured images.\n\nThe system requires substantial lighting to achieve the necessary exposure for clear images, so diffused LED light panels are employed to illuminate the conveyor with a brightness of 10,000 lux.\n\nIn addition to the hardware setup, there is a mention of a machine learning (ML) pipeline that includes data collection, labeling, model training, error analysis, and deployment. This pipeline is critical for ensuring that the system can accurately classify and analyze the images captured by the cameras. The data collection process is designed to be diverse and continuous to avoid biases and to ensure the classifiers developed are robust and reliable.\n\nThe accompanying visual element likely serves as a graphical representation of the ML pipeline, illustrating the sequential steps from data collection to model deployment. This visual aid helps to conceptualize the workflow and the process involved in creating and implementing a machine learning model within an industrial context.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f5aa2a19-5a20-4a06-ac9a-b23dd6fb0bac": {"__data__": {"id_": "f5aa2a19-5a20-4a06-ac9a-b23dd6fb0bac", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p3_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter involves a process where a large number of images are captured at regular intervals, specifically every 30 minutes, resulting in a collection of 1000 images in each burst. The images are then stored on solid-state drives and subsequently uploaded to a cloud service for storage and possibly further processing.\n\nTo manage the image capturing and saving process, a multithreaded master-slave architecture is employed. This architecture includes a queue system where one thread is dedicated to capturing images and placing them into the queue. Meanwhile, additional threads are tasked with retrieving the images from the queue and saving them to the disk. This setup allows for efficient handling of the image processing workflow.\n\nWhen addressing the complex machine learning (ML) problem of object detection and classification within these images, two approaches are considered. The first approach is to use an end-to-end model that performs object detection and classification tasks in a single step. This model would identify the type of object, its color, and whether it is food or non-food.\n\nThe second approach, which is preferred, involves dividing the problem into smaller, more manageable subproblems, each with its own sub-classifier. The results from these sub-classifiers are then combined to achieve the final classification. This method has distinct advantages: it allows for pinpointing the exact performance bottlenecks within the pipeline, providing a more focused strategy for problem-solving. Additionally, smaller classifiers are simpler to debug and iterate through the machine learning development cycle.\n\nThe process of splitting the problem into", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3e7e519e-aa49-485a-9516-3da0703210c1": {"__data__": {"id_": "3e7e519e-aa49-485a-9516-3da0703210c1", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p4_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The content you provided seems to be related to a recycling application focused on PET (Polyethylene Terephthalate) bottles. It outlines a system that uses various technologies and machine learning models to classify and detect objects, specifically bottles, for recycling purposes.\n\nThe system is described as having an object detection model that can differentiate between a bottle and no bottle. Once a bottle is detected, it is further classified by type, color, and whether it is food grade or non-food grade. The classification categories for labeling include clear, light blue, brown, green, other colors, and a distinction between food grade and non-food grade items.\n\nThe object detection model mentioned includes YOLO (You Only Look Once) and similar models, which are known for their speed and efficiency in real-time object detection. For further classification, a variety of models are used, such as Resnet, GoogleNet, Squeezenet, ShuffleNet, and EfficientNet, each suited for different aspects like bottle type or color classification.\n\nThe system is designed to be highly efficient, with the object detection model processing multiple images and the classifiers handling a large number of objects within a very short time frame, aiming for real-time processing capabilities.\n\nTo improve the accuracy of the models, a loop of labeling, training, and error analysis is employed, utilizing active learning and human labelers to quickly annotate a vast number of images. Tools such as Pytorch, Wandb, S3, Apache Airflow, and Kubernetes are used", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7e854471-b3b1-495e-a52e-395d4d8814cc": {"__data__": {"id_": "7e854471-b3b1-495e-a52e-395d4d8814cc", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p5_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter appears to be a technical overview of a system used for recycling, specifically focusing on PET (polyethylene terephthalate) recycling. It outlines a process that includes preprocessing, model training, and manual labeling. The system utilizes various technologies and platforms, such as PyTorch for machine learning tasks and AWS (Amazon Web Services) for cloud computing resources. Kubernetes, a system for automating deployment, scaling, and management of containerized applications, is also part of the workflow, along with Airflow, which is a platform to programmatically author, schedule, and monitor workflows.\n\nThe deployment of the models was done locally on an AGX JETSON ORIN, which is a powerful computing platform designed for AI applications. The use of RabbitMQ, a lightweight message broker, facilitated the communication between the image stream and the models, ensuring that objects were retained even if there was a decrease in the execution speed of the models. The system was capable of performing inference on 8 images per second, with an end-to-end time of 800 milliseconds, while handling a stream of 100 images per second.\n\nThe system was installed at a PET recycling facility in W\u00f6llersdorf, Austria, and it includes a proprietary AI named Noesis and an interactive dashboard called Athena. The AI and dashboard allow for real-time monitoring of the plant's throughput and detection of opaque impurities in the input stream, which is crucial for maintaining the quality of the recycled output. The ability to", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e394f503-e227-423e-9a70-f35420faf657": {"__data__": {"id_": "e394f503-e227-423e-9a70-f35420faf657", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p5_2"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a sophisticated recycling system that utilizes artificial intelligence for real-time monitoring and sorting of recyclable materials. The system is designed to identify and categorize different types of materials, such as bottles and cans, as well as detect impurities that could potentially compromise the recycling process. This technology has been implemented to enhance the efficiency of recycling operations by providing immediate feedback on the plant's throughput and identifying less productive times for optimization. Additionally, the system is capable of detecting opaque materials within the recycling stream, which is particularly important for maintaining the quality of the recycled output. The deployment of this AI-driven solution has been carried out at a prominent PET recycling facility in Europe, where it has contributed to the improvement of the plant's utilization factor and the overall recycling process.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b89fe1b4-3c37-4246-a389-eef47b4435d3": {"__data__": {"id_": "b89fe1b4-3c37-4246-a389-eef47b4435d3", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a recycling plant's process of sorting and analyzing various types of plastic bottles. The system in question, named Noesis, is capable of identifying and categorizing bottles based on their color and transparency, which is crucial for ensuring that the output consists of food-grade PET flakes. The categories mentioned include clear, clear sleeved, green, opaque, blue, and others, indicating a range of bottle types that the system can recognize.\n\nAdditionally, there is a mention of a non-food detection feature, which is essential for the plant to monitor the presence of non-food material in their input stream. This is achieved by analyzing visual markers such as the shape of the bottle, its transparency, and branding.\n\nTo facilitate the monitoring and analysis of this data, a highly interactive dashboard named Athena is used. This dashboard provides both live and historical insights, which are likely displayed in a user-friendly and accessible manner, allowing plant operators to make informed decisions based on the data presented.\n\nFurthermore, there are references to throughput analytics and color analytics, which are probably features of the Athena dashboard, providing detailed information on the plant's operations and the material being processed.\n\nLastly, the text includes a local network address, suggesting that the dashboard or system might be accessible within a local network for users at the plant.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2551e1cc-9715-4a85-9320-6197a12bbcac": {"__data__": {"id_": "2551e1cc-9715-4a85-9320-6197a12bbcac", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_2"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a recycling plant's process of sorting materials, specifically focusing on the differentiation between food-grade and non-food-grade PET bottles. The process involves a sophisticated detection system that can identify various bottle characteristics such as color, transparency, and branding to ensure that only food-grade material is processed for recycling into PET flakes. This system is capable of recognizing and categorizing bottles that are clear, sleeved, green, opaque, blue, and other variations. Additionally, there is a mention of an interactive dashboard named \"Athena,\" which is used to visualize analytics and provide both live and historical data insights generated by the detection system. The dashboard appears to offer various analytics such as throughput and color analysis, contributing to the efficiency and effectiveness of the plant's operations. The text also includes a reference to a local server address, suggesting that the dashboard or system might be accessible through an internal network.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d3006594-4482-4783-a338-814d27d65840": {"__data__": {"id_": "d3006594-4482-4783-a338-814d27d65840", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_3"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a sophisticated system designed to analyze and categorize different types of plastic bottles for recycling purposes. This system, referred to as Noesis, is capable of identifying various bottle characteristics such as color and opacity. It can distinguish between opaque bottles and those that are clear, green, blue, or other colors, providing valuable real-time data to a recycling facility.\n\nAdditionally, the system is equipped to differentiate between food and non-food grade materials, which is crucial for plants that produce food-grade PET flakes. It employs visual markers like the shape of the bottle, its transparency, and branding to ensure non-food materials are accurately identified in the input stream.\n\nTo facilitate the monitoring and interpretation of this data, a highly interactive dashboard named Athena is utilized. This dashboard presents both live and historical data, offering a comprehensive view of the insights generated by Noesis. It appears to be a tool that enhances the efficiency and effectiveness of the recycling process by providing detailed analytics on various aspects such as throughput and color distribution of the processed materials.\n\nThe reference to \"localhost:3000\" suggests that the dashboard or the analytics platform is accessible through a local server, possibly for demonstration, testing, or internal use within a secure network.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b4b2a524-c920-443d-bf47-fcec13702dbb": {"__data__": {"id_": "b4b2a524-c920-443d-bf47-fcec13702dbb", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The content you provided suggests that there is a sophisticated system in place for sorting and analyzing materials in a recycling plant. This system, referred to as Noesis, is capable of identifying various types of bottles by their color and transparency, such as clear, green, blue, and opaque bottles. It is particularly focused on ensuring that non-food grade materials are separated from the input stream, as the output is intended to be food-grade PET flakes.\n\nAdditionally, there is a mention of an interactive dashboard named Athena, which is designed to provide both live and historical data on the insights generated by Noesis. This dashboard seems to be a crucial tool for the plant to monitor various metrics, including the throughput of materials being processed and the color distribution of the bottles.\n\nThe reference to \"localhost:3000\" implies that the dashboard or the analytics platform can be accessed locally on a network, likely within the plant's internal systems, for monitoring and analysis purposes. The text also includes what appears to be a table or a set of categories with headers like \"Clear,\" \"Clear Sleeved,\" \"Green,\" \"Opaque,\" \"Others,\" and \"Blue,\" which are likely related to the sorting categories used by the system to classify the materials. There are also sections that seem to be placeholders or indicators for data points, such as \"Non food detection,\" \"Food,\" \"Non-Food,\" and \"Throughput Analytics on Athena,\" which would be populated with relevant data during the plant's operation.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2677b68d-f42f-49c8-b7de-2e17e24e5f11": {"__data__": {"id_": "2677b68d-f42f-49c8-b7de-2e17e24e5f11", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_5"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a sophisticated system designed to analyze and categorize different types of plastic bottles for recycling purposes. This system, referred to as Noesis, is capable of identifying various bottle characteristics such as color and opacity. It can distinguish between opaque bottles and those that are clear, green, blue, or of other colors, providing valuable real-time data to a recycling facility.\n\nThe system is also adept at detecting non-food grade materials within the recycling stream. This is crucial for plants that aim to produce food-grade PET flakes, as they need to ensure that non-food grade materials are not included in their process. The system employs visual markers like the shape of the bottle, its transparency, and branding to accurately sort the materials.\n\nMoreover, the facility utilizes an interactive dashboard named Athena, developed by Vinglabs, to visualize analytics and insights. This dashboard offers both live and historical data, which is essential for monitoring the plant's performance and making informed decisions. It includes various analytics such as throughput and color distribution, which are displayed in a user-friendly manner, likely through charts and graphs that provide a clear representation of the data collected by Noesis.\n\nAdditionally, there are references to specific metrics and analytics, such as the number of items processed, percentages of different categories, and a pie chart that likely illustrates the distribution of food-grade versus non-food grade materials processed by the plant. The interface appears to be accessible through a local web address, indicating that the dashboard is designed for internal use within the", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"5dad8c33-d152-4251-86de-d4c9e08cfc34": {"doc_hash": "2780deadb86946032509cbf5c212e1b20a2a8fdda540831ab49d17dc2a06d303", "ref_doc_id": "node-0"}, "b40a4533-3bae-4625-9427-9019419569d9": {"doc_hash": "6bdb9b31b351b92d919dace8422baaa0a09477475fb85f4fad144f2215e942f0", "ref_doc_id": "node-0"}, "ef4d06d7-ff96-4cb7-bc4c-7dc16e9cf395": {"doc_hash": "3d084d16f1492dd5198967b19d28f917364bde93e83da540635ab991db6a8995", "ref_doc_id": "node-0"}, "40da949f-6a89-47f0-afad-30818be91c9b": {"doc_hash": "9fd6742f120bce9a815977725b947f74cb288c8a611976e03bccee8e45fb75ee", "ref_doc_id": "node-0"}, "1cecfbfa-bd43-41c1-9ff8-a5d93f920752": {"doc_hash": "289f94e833bf572254fbb094817c83beede346797778e417a21ecdd04b2316dc", "ref_doc_id": "node-0"}, "b43b76b8-79f9-4768-9fdc-f9b1811d000d": {"doc_hash": "d4cd3819dc28b2d695a39f1adff347fb424e79d748e40aa774d852dab23adf1c", "ref_doc_id": "node-0"}, "1b6ba581-e04a-41da-9c9c-a560fc9a5809": {"doc_hash": "bde79e5711dfe8a26f28c33b3dd3a252cafb289c18ced03ba1af893acc23b6b1", "ref_doc_id": "node-0"}, "b78c7981-a043-4911-9d8e-2af26d86f47b": {"doc_hash": "60d272811fe81d918c2b965d93179dd2a254054fea2e3e5c646051a337bbadb9", "ref_doc_id": "node-0"}, "node-0": {"doc_hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "ref_doc_id": "aeaf2ba9-3618-4a99-898b-4bd941cd1a70"}, "e4e7f5fb-6fc1-413e-8013-b0ab34aaa477": {"doc_hash": "a9b4fe4f755b14b418d9ae46fb60759be8f1274e80c0837edc2b5878973c65d2", "ref_doc_id": "node-1"}, "3fdb0b6f-13b0-45f2-8d7d-92673c9e9f45": {"doc_hash": "221ecd3376f86b40ff1a5366fb441cd123671f723d8f7b842d01ab9d3c63633d", "ref_doc_id": "node-1"}, "f08b1c79-4da9-4eee-8d75-6377cc1fc47a": {"doc_hash": "4ff3bbd107c1ea457fa4076338d566f183657d76444b8fb215ad54c606a6fc21", "ref_doc_id": "node-1"}, "741df109-64d7-4014-978f-ff683a874623": {"doc_hash": "a384683e68cf59351869a34b0da11e0e50edc596d87423a3160a8b757613e22b", "ref_doc_id": "node-1"}, "c0aee3bd-fe39-45b9-b4e3-3f716f6a9cf5": {"doc_hash": "5fafd82d970ad5c4384a7e84c188dac385137464edb9a090f7c9d857aec8cd4f", "ref_doc_id": "node-1"}, "8e29643f-d92a-444e-8ae4-9a91366f7892": {"doc_hash": "11e8a3abc6e1507ede7c2542a6e3e987459e03b5c61610eb3d6d1e478be6e35e", "ref_doc_id": "node-1"}, "6608ad4d-3e2c-4d2a-8d77-051d29bad800": {"doc_hash": "553da9a602907d109c17152481d5c71fcfdd641b76691a1d4d8af918c4ef4cdb", "ref_doc_id": "node-1"}, "078c9d85-5279-41f2-95f0-c54582a0dce8": {"doc_hash": "5fafd82d970ad5c4384a7e84c188dac385137464edb9a090f7c9d857aec8cd4f", "ref_doc_id": "node-1"}, "node-1": {"doc_hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "ref_doc_id": "aeaf2ba9-3618-4a99-898b-4bd941cd1a70"}, "5f72e838-dff6-464b-81e6-32b7702d5457": {"doc_hash": "87668f8da7d051aa9022d0a181f7bf298032a6a0c21c2b9904d5a749798594ed", "ref_doc_id": "node-2"}, "471c068b-1bb1-4183-b3f5-423e399d32c6": {"doc_hash": "2b980ee500b8e2cb2698952bbbd698bdabbd675f32a9a8101fe06a15cc0b53f0", "ref_doc_id": "node-2"}, "ad2c688e-f8a2-42a9-b107-65b95b04bd59": {"doc_hash": "aff666267bbafc4f01100cedfdf3e202b8ae4458c1e65e5704247bd03d4d28fd", "ref_doc_id": "node-2"}, "02baf39f-64cd-43fb-b364-07660debf40b": {"doc_hash": "e59099822145a249f4052a777b945b2671e327c0944efb3790a3dd7b2aab2368", "ref_doc_id": "node-2"}, "2b9551d2-6ebf-47e8-8a76-1cef93313552": {"doc_hash": "e31584fb194d5fbf7c3be050a53b7dc5c2c8aa9dbe5cd929f721330b8c25bb8c", "ref_doc_id": "node-2"}, "node-2": {"doc_hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "ref_doc_id": "aeaf2ba9-3618-4a99-898b-4bd941cd1a70"}, "adf083e2-9d2e-4a57-ae26-8ea181edad1d": {"doc_hash": "5df567e02bfd09c05de979cbb94842b8dd35db15a6f4f934fb5ef17aed5362df"}, "4a796597-b7c8-44fe-87c4-bb32511e611a": {"doc_hash": "dc27097fe601da5dea46c19bbcd1e930f163c8ca591c35ac8e1fcddfd3601a4c"}, "97cd8e28-9897-40d4-b554-e4abc03c0be4": {"doc_hash": "739e3fa1f0269a280c134f543bfb80573cb5de01f54579d983adff8b5e6d355e"}, "f5aa2a19-5a20-4a06-ac9a-b23dd6fb0bac": {"doc_hash": "5f7c53251dc13eb3e3acc060199ee74ad774fed545891c87b5539fa630563572"}, "3e7e519e-aa49-485a-9516-3da0703210c1": {"doc_hash": "5b7ab8ed52ed7285df826857a583c871b7003fd52cb3d21c39a3a2780e3d84da"}, "7e854471-b3b1-495e-a52e-395d4d8814cc": {"doc_hash": "0eb135d99a08981ef1054d0a8593e2ea9c722122ae0a229b523baebfa1ee4037"}, "e394f503-e227-423e-9a70-f35420faf657": {"doc_hash": "070665602f13763233ff22b2961f4bbaebef14b8cbed9fbe36cce6b2fe4f8d4c"}, "b89fe1b4-3c37-4246-a389-eef47b4435d3": {"doc_hash": "d606ce1a3da142d9c419bdf287386499a0b4d715c9ddb26b9a0a0490287dc687"}, "2551e1cc-9715-4a85-9320-6197a12bbcac": {"doc_hash": "e188b33a241da09c1b17196ccd416b73b124c0f3403d0e287e79bb149a0473cc"}, "d3006594-4482-4783-a338-814d27d65840": {"doc_hash": "39f6e7f52aaa71b8dd2bdd8b34de579b3015b76e8391b7322d10fb6a68de3bf1"}, "b4b2a524-c920-443d-bf47-fcec13702dbb": {"doc_hash": "eddb3a74ed59ffb63fb3cd1336462b02c3a9a422bf0329224cb2c7b8e0f18d3b"}, "2677b68d-f42f-49c8-b7de-2e17e24e5f11": {"doc_hash": "7b7b040a655f379ba6470cadbc8e0eaf1555deed33d63de1cb5e4c4d9028b0a8"}}, "docstore/ref_doc_info": {"node-0": {"node_ids": ["5dad8c33-d152-4251-86de-d4c9e08cfc34", "b40a4533-3bae-4625-9427-9019419569d9", "ef4d06d7-ff96-4cb7-bc4c-7dc16e9cf395", "40da949f-6a89-47f0-afad-30818be91c9b", "1cecfbfa-bd43-41c1-9ff8-a5d93f920752", "b43b76b8-79f9-4768-9fdc-f9b1811d000d", "1b6ba581-e04a-41da-9c9c-a560fc9a5809", "b78c7981-a043-4911-9d8e-2af26d86f47b"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}}, "aeaf2ba9-3618-4a99-898b-4bd941cd1a70": {"node_ids": ["node-0", "node-1", "node-2"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}}, "node-1": {"node_ids": ["e4e7f5fb-6fc1-413e-8013-b0ab34aaa477", "3fdb0b6f-13b0-45f2-8d7d-92673c9e9f45", "f08b1c79-4da9-4eee-8d75-6377cc1fc47a", "741df109-64d7-4014-978f-ff683a874623", "c0aee3bd-fe39-45b9-b4e3-3f716f6a9cf5", "8e29643f-d92a-444e-8ae4-9a91366f7892", "6608ad4d-3e2c-4d2a-8d77-051d29bad800", "078c9d85-5279-41f2-95f0-c54582a0dce8"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}}, "node-2": {"node_ids": ["5f72e838-dff6-464b-81e6-32b7702d5457", "471c068b-1bb1-4183-b3f5-423e399d32c6", "ad2c688e-f8a2-42a9-b107-65b95b04bd59", "02baf39f-64cd-43fb-b364-07660debf40b", "2b9551d2-6ebf-47e8-8a76-1cef93313552"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}}}}